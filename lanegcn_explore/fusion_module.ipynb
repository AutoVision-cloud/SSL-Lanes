{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e857cf2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0640298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from fractions import gcd\n",
    "from numbers import Number\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from numpy import float64, ndarray\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d80b1e1",
   "metadata": {},
   "source": [
    "## Load from Data storage path into data_argo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eebc8e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('../LaneGCN/', \"dataset\",\"preprocess\", \"val_crs_dist6_angle90.p\")\n",
    "data_argo = np.load(data_path, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d97680f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx\n",
      "city\n",
      "feats\n",
      "ctrs\n",
      "orig\n",
      "theta\n",
      "rot\n",
      "gt_preds\n",
      "has_preds\n",
      "graph\n"
     ]
    }
   ],
   "source": [
    "## CHOOSE SCENE!\n",
    "idx = 3\n",
    "for keys,_ in data_argo[idx].items():\n",
    "    print(keys)\n",
    "    \n",
    "data = data_argo[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46be56ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "config = dict()\n",
    "\"\"\"Train\"\"\"\n",
    "config[\"display_iters\"] = 205942\n",
    "config[\"val_iters\"] = 205942 * 2\n",
    "config[\"save_freq\"] = 1.0\n",
    "config[\"epoch\"] = 0\n",
    "config[\"horovod\"] = True\n",
    "config[\"opt\"] = \"adam\"\n",
    "config[\"num_epochs\"] = 36\n",
    "config[\"lr\"] = [1e-3, 1e-4]\n",
    "config[\"lr_epochs\"] = [32]\n",
    "#config[\"lr_func\"] = StepLR(config[\"lr\"], config[\"lr_epochs\"])\n",
    "\n",
    "config[\"batch_size\"] = 32\n",
    "config[\"val_batch_size\"] = 32\n",
    "config[\"workers\"] = 0\n",
    "config[\"val_workers\"] = config[\"workers\"]\n",
    "\n",
    "\"\"\"Model\"\"\"\n",
    "config[\"rot_aug\"] = False\n",
    "config[\"pred_range\"] = [-100.0, 100.0, -100.0, 100.0]\n",
    "config[\"num_scales\"] = 6\n",
    "config[\"n_actor\"] = 128\n",
    "config[\"n_map\"] = 128\n",
    "config[\"actor2map_dist\"] = 7.0\n",
    "config[\"map2actor_dist\"] = 6.0\n",
    "config[\"actor2actor_dist\"] = 100.0\n",
    "config[\"pred_size\"] = 30\n",
    "config[\"pred_step\"] = 1\n",
    "config[\"num_preds\"] = config[\"pred_size\"] // config[\"pred_step\"]\n",
    "config[\"num_mods\"] = 6\n",
    "config[\"cls_coef\"] = 1.0\n",
    "config[\"reg_coef\"] = 1.0\n",
    "config[\"mgn\"] = 0.2\n",
    "config[\"cls_th\"] = 2.0\n",
    "config[\"cls_ignore\"] = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed5ff24",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58152a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, n_in, n_out, norm='GN', ng=32, act=True):\n",
    "        super(Linear, self).__init__()\n",
    "        assert(norm in ['GN', 'BN', 'SyncBN'])\n",
    "\n",
    "        self.linear = nn.Linear(n_in, n_out, bias=False)\n",
    "        \n",
    "        if norm == 'GN':\n",
    "            self.norm = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "        elif norm == 'BN':\n",
    "            self.norm = nn.BatchNorm1d(n_out)\n",
    "        else:\n",
    "            exit('SyncBN has not been added!')\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = self.norm(out)\n",
    "        if self.act:\n",
    "            out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e05fd29",
   "metadata": {},
   "source": [
    "## Attention layer to be used for 3 kinds of fusion (A2A, L2A, A2L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14845dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dist vector:  torch.Size([5, 100, 2])\n",
      "Shape of idcs:  torch.Size([97, 2])\n",
      "Agent idxs:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4])\n",
      "Map idxs:  tensor([29, 38, 49, 50, 59, 72, 74, 75, 79, 85, 88,  7, 10, 16, 18, 66,  2, 11,\n",
      "        27, 32, 51, 58, 60, 68, 70, 73, 76, 77, 78, 81, 82, 84, 92,  5,  8, 14,\n",
      "        29, 38, 49, 50, 52, 59, 63, 72, 74, 75, 79, 83, 85, 88, 93, 97, 98,  1,\n",
      "         4,  9, 12, 13, 15, 21, 24, 25, 26, 30, 31, 33, 34, 36, 37, 39, 42, 45,\n",
      "        47, 51, 52, 53, 54, 57, 61, 62, 63, 65, 67, 70, 77, 78, 80, 81, 82, 83,\n",
      "        84, 89, 90, 91, 92, 95, 97])\n",
      "Dist shape:  torch.Size([317, 2])\n",
      "\n",
      "Vector be concat shapes:  torch.Size([317, 2]) torch.Size([317, 12]) torch.Size([317, 128])\n"
     ]
    }
   ],
   "source": [
    "agt_ctrs = torch.randn([3, 5, 2])\n",
    "ctx_ctrs = torch.randn([3, 100, 2])\n",
    "\n",
    "hi, wi = [], []\n",
    "hi_count, wi_count = 0, 0\n",
    "        \n",
    "for i in range(3):\n",
    "    dist = agt_ctrs[i].view(-1, 1, 2) - ctx_ctrs[i].view(1, -1, 2)\n",
    "    \n",
    "    if i==0:\n",
    "        print(\"Shape of dist vector: \", dist.shape)\n",
    "    dist = torch.sqrt((dist ** 2).sum(2))\n",
    "    mask = dist <= 1\n",
    "    idcs = torch.nonzero(mask, as_tuple=False)   \n",
    "    if i==0:\n",
    "        print(\"Shape of idcs: \", idcs.shape)\n",
    "    # hi-agt; wi-ctx\n",
    "    hi.append(idcs[:, 0] + hi_count)\n",
    "    wi.append(idcs[:, 1] + wi_count)\n",
    "    hi_count += 5\n",
    "    wi_count += 100\n",
    "        \n",
    "print(\"Agent idxs: \", hi[0])\n",
    "print(\"Map idxs: \", wi[0])\n",
    "hi = torch.cat(hi, 0)\n",
    "wi = torch.cat(wi, 0)\n",
    "agt_ctrs = agt_ctrs.view(-1, 2)\n",
    "ctx_ctrs = ctx_ctrs.view(-1, 2)\n",
    "\n",
    "dist = agt_ctrs[hi] - ctx_ctrs[wi]\n",
    "print(\"Dist shape: \", dist.shape)\n",
    "\n",
    "agt = torch.randn([15, 12])\n",
    "ctx = torch.randn([300, 128])\n",
    "\n",
    "print(\"\\nVector be concat shapes: \", dist.shape, agt[hi].shape, ctx[wi].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80657706",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Say we have actor x_i. The map nodes are denoted by y_j.\n",
    "\n",
    "First get dist of all relevant i's from all relevant j's.\n",
    "\n",
    "Concat this with [dist_ij, x_i, y_j]. \n",
    "\n",
    "Sum all [dist_ij, x_i, y_j] vectors for a particular x_i. This is the new vector for x_i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "164a90b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Att(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention block to pass context nodes information to target nodes\n",
    "    This is used in Actor2Map, Actor2Actor, Map2Actor\n",
    "    \"\"\"\n",
    "    def __init__(self, n_agt, n_ctx):\n",
    "        # n_agt: dim of target ; n_ctx: dimension of src\n",
    "        super(Att, self).__init__()\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "        \n",
    "        # to convert dist between a src and target to a src-shaped tensor\n",
    "        self.dist = nn.Sequential(\n",
    "                    nn.Linear(2, n_ctx),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    Linear(n_ctx, n_ctx, norm, n_g)\n",
    "                    )\n",
    "        \n",
    "        # Convert target vectors to src dim for concat (not sure why this is needed)\n",
    "        self.query = Linear(n_agt, n_ctx, norm=norm, ng=ng)\n",
    "        \n",
    "        # Convert the concat-ed tensor back to target-dim\n",
    "        self.ctx = nn.Sequential(\n",
    "            Linear(3 * n_ctx, n_agt, norm=norm, ng=ng),\n",
    "            nn.Linear(n_agt, n_agt, bias=False),\n",
    "        )\n",
    "        \n",
    "        # linear transform on target\n",
    "        self.agt = nn.Linear(n_agt, n_agt, bias=False)\n",
    "        \n",
    "        self.norm = nn.GroupNorm(gcd(ng, n_agt), n_agt)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # final transform to be added to res\n",
    "        self.linear = Linear(n_agt, n_agt, norm=norm, ng=ng, act=False)\n",
    "       \n",
    "    \n",
    "    def forward(self, \n",
    "                agts, agt_idcs, agt_ctrs, \n",
    "                ctx, ctx_idcs, ctx_ctrs, \n",
    "                dist_th):\n",
    "        res = agts\n",
    "        \n",
    "        if len(ctx) == 0:\n",
    "            agts = self.agt(agts)\n",
    "            agts = self.relu(agts)\n",
    "            agts = self.linear(agts)\n",
    "            agts += res\n",
    "            agts = self.relu(agts)\n",
    "            return agts\n",
    "\n",
    "        batch_size = len(agt_idcs)\n",
    "        \n",
    "        hi, wi = [], []\n",
    "        hi_count, wi_count = 0, 0\n",
    "        \n",
    "        # go over every batch separately\n",
    "        for i in range(batch_size):\n",
    "            # distance thresholding\n",
    "            dist = agt_ctrs[i].view(-1, 1, 2) - ctx_ctrs[i].view(1, -1, 2)\n",
    "            dist = torch.sqrt((dist ** 2).sum(2))\n",
    "            mask = dist <= dist_th\n",
    "            \n",
    "            idcs = torch.nonzero(mask, as_tuple=False)\n",
    "            if len(idcs) == 0:\n",
    "                continue\n",
    "                \n",
    "            hi.append(idcs[:, 0] + hi_count)\n",
    "            wi.append(idcs[:, 1] + wi_count)\n",
    "            hi_count += len(agt_idcs[i])\n",
    "            wi_count += len(ctx_idcs[i])\n",
    "            \n",
    "        # src: wi, target: hi\n",
    "        hi = torch.cat(hi, 0)\n",
    "        wi = torch.cat(wi, 0)\n",
    "        \n",
    "        # distance encoding between src and target less than a threshold\n",
    "        agt_ctrs = torch.cat(agt_ctrs, 0)\n",
    "        ctx_ctrs = torch.cat(ctx_ctrs, 0)\n",
    "        dist = agt_ctrs[hi] - ctx_ctrs[wi]\n",
    "        dist = self.dist(dist)\n",
    "        \n",
    "        # linear transform for appropriate targets\n",
    "        query = self.query(agts[hi])\n",
    "        \n",
    "        # concat and transform\n",
    "        ctx = ctx[wi]\n",
    "        ctx = torch.cat((dist, query, ctx), 1)\n",
    "        ctx = self.ctx(ctx)\n",
    "        \n",
    "        # combine transformed src with targets\n",
    "        agts = self.agt(agts)\n",
    "        agts.index_add_(0, hi, ctx)\n",
    "        \n",
    "        # normalize, activate\n",
    "        agts = self.norm(agts)\n",
    "        agts = self.relu(agts)\n",
    "        \n",
    "        agts = self.linear(agts)\n",
    "        \n",
    "        agts += res\n",
    "        agts = self.relu(agts)\n",
    "        return agts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9e2eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl_venv",
   "language": "python",
   "name": "ssl_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64675632",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cad4242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from scipy import sparse\n",
    "import os\n",
    "import copy\n",
    "from argoverse.data_loading.argoverse_forecasting_loader import ArgoverseForecastingLoader\n",
    "from argoverse.map_representation.map_api import ArgoverseMap\n",
    "from skimage.transform import rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ddafef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from fractions import gcd\n",
    "from numbers import Number\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from numpy import float64, ndarray\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa28b8d",
   "metadata": {},
   "source": [
    "## Load from Data storage path into data_argo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a406add",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('../LaneGCN/', \"dataset\",\"preprocess\", \"val_crs_dist6_angle90.p\")\n",
    "data_argo = np.load(data_path, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26cb94e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx\n",
      "city\n",
      "feats\n",
      "ctrs\n",
      "orig\n",
      "theta\n",
      "rot\n",
      "gt_preds\n",
      "has_preds\n",
      "graph\n"
     ]
    }
   ],
   "source": [
    "## CHOOSE SCENE!\n",
    "idx = 3\n",
    "for keys,_ in data_argo[idx].items():\n",
    "    print(keys)\n",
    "    \n",
    "data = data_argo[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b1c8e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "config = dict()\n",
    "\"\"\"Train\"\"\"\n",
    "config[\"display_iters\"] = 205942\n",
    "config[\"val_iters\"] = 205942 * 2\n",
    "config[\"save_freq\"] = 1.0\n",
    "config[\"epoch\"] = 0\n",
    "config[\"horovod\"] = True\n",
    "config[\"opt\"] = \"adam\"\n",
    "config[\"num_epochs\"] = 36\n",
    "config[\"lr\"] = [1e-3, 1e-4]\n",
    "config[\"lr_epochs\"] = [32]\n",
    "#config[\"lr_func\"] = StepLR(config[\"lr\"], config[\"lr_epochs\"])\n",
    "\n",
    "config[\"batch_size\"] = 32\n",
    "config[\"val_batch_size\"] = 32\n",
    "config[\"workers\"] = 0\n",
    "config[\"val_workers\"] = config[\"workers\"]\n",
    "\n",
    "\"\"\"Model\"\"\"\n",
    "config[\"rot_aug\"] = False\n",
    "config[\"pred_range\"] = [-100.0, 100.0, -100.0, 100.0]\n",
    "config[\"num_scales\"] = 6\n",
    "config[\"n_actor\"] = 128\n",
    "config[\"n_map\"] = 128\n",
    "config[\"actor2map_dist\"] = 7.0\n",
    "config[\"map2actor_dist\"] = 6.0\n",
    "config[\"actor2actor_dist\"] = 100.0\n",
    "config[\"pred_size\"] = 30\n",
    "config[\"pred_step\"] = 1\n",
    "config[\"num_preds\"] = config[\"pred_size\"] // config[\"pred_step\"]\n",
    "config[\"num_mods\"] = 6\n",
    "config[\"cls_coef\"] = 1.0\n",
    "config[\"reg_coef\"] = 1.0\n",
    "config[\"mgn\"] = 0.2\n",
    "config[\"cls_th\"] = 2.0\n",
    "config[\"cls_ignore\"] = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca83e437",
   "metadata": {},
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0abc6bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d(nn.Module):\n",
    "    def __init__(self, n_in, n_out, kernel_size=3, stride=1, norm='GN', ng=32, act=True):\n",
    "        super(Conv1d, self).__init__()\n",
    "        assert(norm in ['GN', 'BN', 'SyncBN'])\n",
    "\n",
    "        self.conv = nn.Conv1d(n_in, n_out, kernel_size=kernel_size, padding=(int(kernel_size) - 1) // 2, stride=stride, bias=False)\n",
    "\n",
    "        if norm == 'GN':\n",
    "            self.norm = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "        elif norm == 'BN':\n",
    "            self.norm = nn.BatchNorm1d(n_out)\n",
    "        else:\n",
    "            exit('SyncBN has not been added!')\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.norm(out)\n",
    "        if self.act:\n",
    "            out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8a4487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Res1d(nn.Module):\n",
    "    def __init__(self, n_in, n_out, kernel_size=3, stride=1, norm='GN', ng=32, act=True):\n",
    "        super(Res1d, self).__init__()\n",
    "        assert(norm in ['GN', 'BN', 'SyncBN'])\n",
    "        padding = (int(kernel_size) - 1) // 2\n",
    "        self.conv1 = nn.Conv1d(n_in, n_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
    "        self.conv2 = nn.Conv1d(n_out, n_out, kernel_size=kernel_size, padding=padding, bias=False)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "\n",
    "        # All use name bn1 and bn2 to load imagenet pretrained weights\n",
    "        if norm == 'GN':\n",
    "            self.bn1 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "            self.bn2 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "        elif norm == 'BN':\n",
    "            self.bn1 = nn.BatchNorm1d(n_out)\n",
    "            self.bn2 = nn.BatchNorm1d(n_out)\n",
    "        else:\n",
    "            exit('SyncBN has not been added!')\n",
    "\n",
    "        if stride != 1 or n_out != n_in:\n",
    "            if norm == 'GN':\n",
    "                self.downsample = nn.Sequential(\n",
    "                        nn.Conv1d(n_in, n_out, kernel_size=1, stride=stride, bias=False),\n",
    "                        nn.GroupNorm(gcd(ng, n_out), n_out))\n",
    "            elif norm == 'BN':\n",
    "                self.downsample = nn.Sequential(\n",
    "                        nn.Conv1d(n_in, n_out, kernel_size=1, stride=stride, bias=False),\n",
    "                        nn.BatchNorm1d(n_out))\n",
    "            else:\n",
    "                exit('SyncBN has not been added!')\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "\n",
    "        out += x\n",
    "        if self.act:\n",
    "            out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d249d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, n_in, n_out, norm='GN', ng=32, act=True):\n",
    "        super(Linear, self).__init__()\n",
    "        assert(norm in ['GN', 'BN', 'SyncBN'])\n",
    "\n",
    "        self.linear = nn.Linear(n_in, n_out, bias=False)\n",
    "        \n",
    "        if norm == 'GN':\n",
    "            self.norm = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "        elif norm == 'BN':\n",
    "            self.norm = nn.BatchNorm1d(n_out)\n",
    "        else:\n",
    "            exit('SyncBN has not been added!')\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = self.norm(out)\n",
    "        if self.act:\n",
    "            out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d3caf7",
   "metadata": {},
   "source": [
    "## Actor-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac8af89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num actors:  24 ;\tActors shape:  torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "# actor-gather function\n",
    "# Basic function: convert actor shape from [num, 20, 3] ->[num, 3, 20];; Also generate unique idx for each actor across batches\n",
    "def actor_gather(actors):\n",
    "    batch_size = len(actors)\n",
    "    num_actors = [len(x) for x in actors]\n",
    "    actors = [torch.tensor(x).transpose(1, 2) for x in actors] #(num_actors, 3, 20)\n",
    "    actors = torch.cat(actors, 0)\n",
    "    \n",
    "    actor_idcs = []\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        #---(how to take care of the batch-dimension)\n",
    "        idcs = torch.arange(count, count + num_actors[i]) # say [0,1,2,...10] for batch-1; [11,12,13,...21] for batch-2\n",
    "        actor_idcs.append(idcs) # give arange-ID to actors across batches\n",
    "        count += num_actors[i]\n",
    "    return actors, actor_idcs\n",
    "\n",
    "# input\n",
    "actors = [data['feats']]    \n",
    "actors, actor_idcs = actor_gather(actors)\n",
    "print(\"Num actors: \", len(actors), \";\\tActors shape: \", actors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31af410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define actor-net: essentially a bunch of 1D-Convs with FPN\n",
    "# basic components: Res1D, blocks, groups, lateral, interpolates, outputs\n",
    "# 1 group/1blocks = many Res1Ds; 1 groups = many group; laterals = no of side branch outputs\n",
    "\n",
    "class ActorNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Actor feature extractor with Conv1D\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(ActorNet, self).__init__()\n",
    "        self.config = config\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "        \n",
    "        n_in = 3\n",
    "        n_out = [32, 64, 128]\n",
    "        blocks = [Res1d, Res1d, Res1d]\n",
    "        num_blocks = [2, 2, 2]\n",
    "        \n",
    "        groups = []\n",
    "        # first loop is across no of blocks (here 3!)\n",
    "        for i in range(len(num_blocks)):\n",
    "            group = []\n",
    "            if i == 0:\n",
    "                group.append(blocks[i](n_in, n_out[i], norm=norm, ng=ng))\n",
    "            else:\n",
    "                group.append(blocks[i](n_in, n_out[i], stride=2, norm=norm, ng=ng)) # have a lever to set the stride\n",
    "            \n",
    "            for j in range(1, num_blocks[i]):\n",
    "                group.append(blocks[i](n_out[i], n_out[i], norm=norm, ng=ng))\n",
    "            \n",
    "            groups.append(nn.Sequential(*group))\n",
    "            \n",
    "            n_in = n_out[i]    \n",
    "        \n",
    "        self.groups = nn.ModuleList(groups) # moduleLIST: groups\n",
    "            \n",
    "        # lateral\n",
    "        n = config[\"n_actor\"]\n",
    "        lateral = []\n",
    "        for i in range(len(n_out)):\n",
    "            lateral.append(Conv1d(n_out[i], n, norm=norm, ng=ng, act=False)) # convert every middle representation across len(n_out) layers to 128 dim \n",
    "        self.lateral = nn.ModuleList(lateral) # moduleLIST: lateral\n",
    "        \n",
    "        # output: just a transformation\n",
    "        self.output = Res1d(n, n, norm=norm, ng=ng)\n",
    "        \n",
    "        \n",
    "    def forward(self, actors):\n",
    "        out = actors\n",
    "        \n",
    "        outputs = []\n",
    "        ## do convs with groups\n",
    "        for i in range(len(self.groups)):\n",
    "            out = self.groups[i](out)\n",
    "            outputs.append(out)\n",
    "            \n",
    "        ## interpolate and lateral add\n",
    "        out = self.lateral[-1](outputs[-1])\n",
    "        for i in range(len(outputs) - 2, -1, -1):\n",
    "            out = F.interpolate(out, scale_factor=2, mode=\"linear\", align_corners=False)\n",
    "            out += self.lateral[i](outputs[i])\n",
    "        \n",
    "        ## output\n",
    "        out = self.output(out)[:, :, -1] # take only the last time-step's representation\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96a36046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_438620/4167187313.py:12: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  self.bn1 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
      "/tmp/ipykernel_438620/4167187313.py:13: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  self.bn2 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
      "/tmp/ipykernel_438620/4167187313.py:24: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  nn.GroupNorm(gcd(ng, n_out), n_out))\n",
      "/tmp/ipykernel_438620/1811081152.py:9: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  self.norm = nn.GroupNorm(gcd(ng, n_out), n_out)\n"
     ]
    }
   ],
   "source": [
    "actor_net = ActorNet(config)\n",
    "actors = actor_net(actors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8532b355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of actors after actor-net:  torch.Size([24, 128])\n"
     ]
    }
   ],
   "source": [
    "## Input: actor features [num_actors per scene*batch, 3, 20]\n",
    "## Output: actor features at the last time-step [num_actors per scene*batch, 128]\n",
    "print(\"Shape of actors after actor-net: \", actors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8c67e3",
   "metadata": {},
   "source": [
    "## Map-Gather (Organize Map Data for Map-Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "023d330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on 2 graphs\n",
    "graphs = [data_argo[idx]['graph'] #]\n",
    "          , data_argo[idx+1]['graph']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1d7e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_gather(graphs):\n",
    "    batch_size = len(graphs)\n",
    "    node_idcs = []\n",
    "    count = 0\n",
    "    counts = []\n",
    "    for i in range(batch_size):\n",
    "        counts.append(count)\n",
    "        idcs = torch.arange(count, count + graphs[i][\"num_nodes\"])\n",
    "        node_idcs.append(idcs)\n",
    "        count = count + graphs[i][\"num_nodes\"]\n",
    "    \n",
    "    graph = dict()\n",
    "    graph[\"idcs\"] = node_idcs\n",
    "    \n",
    "    #-----------Features and Attributes Order for Lane-Conv (how to take care of the batch-dimension)\n",
    "    graph[\"ctrs\"] = [torch.tensor(x[\"ctrs\"]) for x in graphs]\n",
    "    print(\"Shape of graph[ctrs]: G1 \", graph['ctrs'][0].shape, \"G2: \", graph['ctrs'][1].shape)\n",
    "    \n",
    "    for key in [\"feats\", \"turn\", \"control\", \"intersect\"]:\n",
    "        graph[key] = torch.cat([torch.tensor(x[key]) for x in graphs], 0)\n",
    "        print(\"Shape of \", key, ':\\t', graph[key].shape)\n",
    "        \n",
    "    #-----------Edges Order for Lane-Conv (how to take care of the batch-dimension)\n",
    "    #------k1: pre or suc or left or right keys; i: 6(because 6 scales/dilations of lane-conv); k2:u/v keys\n",
    "    for k1 in [\"pre\", \"suc\"]: # go through graph keys predecessor and successor\n",
    "        graph[k1] = []\n",
    "        for i in range(len(graphs[0][\"pre\"])):\n",
    "            graph[k1].append(dict())\n",
    "            for k2 in ['u', 'v']:\n",
    "                 graph[k1][i][k2] = torch.cat([torch.LongTensor(graphs[j][k1][i][k2]) + counts[j] \n",
    "                                               for j in range(batch_size)], 0) \n",
    "                    # add proper index counters so each node is unique and concatenate\n",
    "                    \n",
    "    print(\"At scale 6, what does the predecessor u-v's look like: ?\", \"u: \", graph['pre'][5]['u'].shape, '\\tv:', \n",
    "          graph['pre'][5]['v'].shape)\n",
    "    \n",
    "    #------For left and right, there is no dilation! SO loop through only k1 and k2\n",
    "    for k1 in [\"left\", \"right\"]:\n",
    "        graph[k1] = dict()\n",
    "        for k2 in [\"u\", \"v\"]:\n",
    "            temp = [torch.LongTensor(graphs[i][k1][k2]) + counts[i] for i in range(batch_size)]\n",
    "            temp = [\n",
    "                x if x.dim() > 0 else graph[\"pre\"][0][\"u\"].new().resize_(0)\n",
    "                for x in temp\n",
    "            ]\n",
    "            graph[k1][k2] = torch.cat(temp)\n",
    "            \n",
    "            \n",
    "    print(\"Shape of individual left-right graphs?\", len(graphs[0][k1][k2]), ';\\t', len(graphs[1][k1][k2]))\n",
    "    print(\"What does left-right look like ?\", \"u: \", graph['left']['u'].shape, '\\tv:', \n",
    "          graph['left']['v'].shape)\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca81c4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of graph[ctrs]: G1  torch.Size([1017, 2]) G2:  torch.Size([1476, 2])\n",
      "Shape of  feats :\t torch.Size([2493, 2])\n",
      "Shape of  turn :\t torch.Size([2493, 2])\n",
      "Shape of  control :\t torch.Size([2493])\n",
      "Shape of  intersect :\t torch.Size([2493])\n",
      "At scale 6, what does the predecessor u-v's look like: ? u:  torch.Size([3137]) \tv: torch.Size([3137])\n",
      "Shape of individual left-right graphs? 558 ;\t 270\n",
      "What does left-right look like ? u:  torch.Size([828]) \tv: torch.Size([828])\n"
     ]
    }
   ],
   "source": [
    "graph = graph_gather(graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3717cf3",
   "metadata": {},
   "source": [
    "## Map-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3df0f828",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 scales so Keys are:  ['ctr', 'norm', 'ctr2', 'left', 'right', 'pre0', 'suc0', 'pre1', 'suc1', 'pre2', 'suc2', 'pre3', 'suc3', 'pre4', 'suc4', 'pre5', 'suc5']\n",
      "\n",
      "Init fuse dict:  {'ctr': [], 'norm': [], 'ctr2': [], 'left': [], 'right': [], 'pre0': [], 'suc0': [], 'pre1': [], 'suc1': [], 'pre2': [], 'suc2': [], 'pre3': [], 'suc3': [], 'pre4': [], 'suc4': [], 'pre5': [], 'suc5': []}\n",
      "\n",
      "The fuse module is: \n",
      " {'ctr': [Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False)], 'norm': [GroupNorm(1, 128, eps=1e-05, affine=True), GroupNorm(1, 128, eps=1e-05, affine=True), GroupNorm(1, 128, eps=1e-05, affine=True), GroupNorm(1, 128, eps=1e-05, affine=True)], 'ctr2': [Linear(\n",
      "  (linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "  (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "), Linear(\n",
      "  (linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "  (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "), Linear(\n",
      "  (linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "  (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "), Linear(\n",
      "  (linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "  (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")], 'left': [Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False)], 'right': [Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False)], 'pre0': [Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False)], 'suc0': [Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False)], 'pre1': [Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False)], 'suc1': [Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False)], 'pre2': [Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False)], 'suc2': [Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False)], 'pre3': [Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False)], 'suc3': [Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False)], 'pre4': [Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False)], 'suc4': [Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False)], 'pre5': [Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False)], 'suc5': [Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False), Linear(in_features=128, out_features=128, bias=False)]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_438620/457146498.py:21: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  fuse[key].append(nn.GroupNorm(gcd(ng, n_map), n_map))\n",
      "/tmp/ipykernel_438620/3573889610.py:9: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  self.norm = nn.GroupNorm(gcd(ng, n_out), n_out)\n"
     ]
    }
   ],
   "source": [
    "# check which layer is for what!\n",
    "# self.input (Linear/RELU/Linear), self.seg (Linear/RELU/Linear), self.fuse(4 blocks of lane-conv layers)\n",
    "n_map = config[\"n_map\"]\n",
    "norm = \"GN\"\n",
    "ng = 1\n",
    "\n",
    "keys = [\"ctr\", \"norm\", \"ctr2\", \"left\", \"right\"]\n",
    "for i in range(config[\"num_scales\"]):\n",
    "    keys.append(\"pre\" + str(i))\n",
    "    keys.append(\"suc\" + str(i))\n",
    "print(\"6 scales so Keys are: \", keys)\n",
    "\n",
    "fuse = dict()\n",
    "for key in keys:\n",
    "    fuse[key] = []\n",
    "print(\"\\nInit fuse dict: \", fuse)\n",
    "\n",
    "for i in range(4):\n",
    "    for key in fuse:\n",
    "        if key in [\"norm\"]:\n",
    "                    fuse[key].append(nn.GroupNorm(gcd(ng, n_map), n_map))\n",
    "        elif key in [\"ctr2\"]:\n",
    "            fuse[key].append(Linear(n_map, n_map, norm=norm, ng=ng, act=False))\n",
    "        else:\n",
    "            fuse[key].append(nn.Linear(n_map, n_map, bias=False))\n",
    "\n",
    "print(\"\\nThe fuse module is: \\n\",fuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65760d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2493, 128])\n",
      "Print an example of graph:  tensor([   1,    2,    3,  ..., 2490, 2491, 2492])\n",
      "tensor([   1,    2,    3,  ..., 2490, 2491, 2492])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_438620/3573889610.py:9: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  self.norm = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
      "/tmp/ipykernel_438620/2333194333.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  index = torch.tensor(graph[k1][k2][\"u\"].clone(), dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "# Implement eqn 1 of LaneGCN: output should be [[number of nodes x 128]]\n",
    "inputnn = nn.Sequential(\n",
    "            nn.Linear(2, n_map),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Linear(n_map, n_map, norm=norm, ng=ng, act=False),\n",
    "        )\n",
    "seg = nn.Sequential(\n",
    "            nn.Linear(2, n_map),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Linear(n_map, n_map, norm=norm, ng=ng, act=False),\n",
    "        )\n",
    "    \n",
    "ctrs = torch.cat(graph[\"ctrs\"], 0)\n",
    "feat = inputnn(ctrs)\n",
    "feat += seg(graph[\"feats\"])\n",
    "feat = nn.ReLU()(feat)\n",
    "\n",
    "print(feat.shape)\n",
    "\n",
    "## Next implement Eqn-3 without the XW0\n",
    "\"\"\"fuse map\"\"\"\n",
    "res = feat\n",
    "for i in range(len(fuse[\"ctr\"])): # essentially looping 4 times\n",
    "    temp = fuse[\"ctr\"][i](feat) # first linear\n",
    "    \n",
    "    if i==0:\n",
    "        k1 = 'pre'\n",
    "        k2 = 0\n",
    "        print(\"Print an example of graph: \", graph['pre'][0]['u'])\n",
    "    \n",
    "        index = torch.tensor(graph[k1][k2][\"u\"].clone(), dtype=torch.long)\n",
    "        print(index)\n",
    "    \n",
    "    for key in fuse:\n",
    "        if key.startswith(\"pre\") or key.startswith(\"suc\"):\n",
    "            k1 = key[:3]\n",
    "            k2 = int(key[3:])\n",
    "            temp.index_add_(\n",
    "                0,\n",
    "                graph[k1][k2][\"u\"],\n",
    "                fuse[key][i](feat[graph[k1][k2][\"v\"]]),\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27a99278",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Map Graph feature extractor with LaneGraphCNN\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(MapNet, self).__init__()\n",
    "        self.config = config\n",
    "        n_map = config[\"n_map\"]\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        self.input = nn.Sequential(\n",
    "            nn.Linear(2, n_map),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Linear(n_map, n_map, norm=norm, ng=ng, act=False),\n",
    "        )\n",
    "        self.seg = nn.Sequential(\n",
    "            nn.Linear(2, n_map),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Linear(n_map, n_map, norm=norm, ng=ng, act=False),\n",
    "        )\n",
    "\n",
    "        keys = [\"ctr\", \"norm\", \"ctr2\", \"left\", \"right\"]\n",
    "        for i in range(config[\"num_scales\"]):\n",
    "            keys.append(\"pre\" + str(i))\n",
    "            keys.append(\"suc\" + str(i))\n",
    "\n",
    "        fuse = dict()\n",
    "        for key in keys:\n",
    "            fuse[key] = []\n",
    "\n",
    "        for i in range(4):\n",
    "            for key in fuse:\n",
    "                if key in [\"norm\"]:\n",
    "                    fuse[key].append(nn.GroupNorm(gcd(ng, n_map), n_map))\n",
    "                elif key in [\"ctr2\"]:\n",
    "                    fuse[key].append(Linear(n_map, n_map, norm=norm, ng=ng, act=False))\n",
    "                else:\n",
    "                    fuse[key].append(nn.Linear(n_map, n_map, bias=False))\n",
    "\n",
    "        for key in fuse:\n",
    "            fuse[key] = nn.ModuleList(fuse[key])\n",
    "        self.fuse = nn.ModuleDict(fuse)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, graph):\n",
    "        if (\n",
    "            len(graph[\"feats\"]) == 0\n",
    "            or len(graph[\"pre\"][-1][\"u\"]) == 0\n",
    "            or len(graph[\"suc\"][-1][\"u\"]) == 0\n",
    "        ):\n",
    "            temp = graph[\"feats\"]\n",
    "            return (\n",
    "                temp.new().resize_(0),\n",
    "                [temp.new().long().resize_(0) for x in graph[\"node_idcs\"]],\n",
    "                temp.new().resize_(0),\n",
    "            )\n",
    "\n",
    "        ctrs = torch.cat(graph[\"ctrs\"], 0)\n",
    "        feat = self.input(ctrs)\n",
    "        feat += self.seg(graph[\"feats\"])\n",
    "        feat = self.relu(feat)\n",
    "\n",
    "        \"\"\"fuse map\"\"\"\n",
    "        res = feat\n",
    "        for i in range(len(self.fuse[\"ctr\"])):\n",
    "            temp = self.fuse[\"ctr\"][i](feat)\n",
    "            for key in self.fuse:\n",
    "                # Eqn-3, third component\n",
    "                if key.startswith(\"pre\") or key.startswith(\"suc\"):\n",
    "                    k1 = key[:3]\n",
    "                    k2 = int(key[3:])\n",
    "                    temp.index_add_(\n",
    "                        0,\n",
    "                        graph[k1][k2][\"u\"],\n",
    "                        self.fuse[key][i](feat[graph[k1][k2][\"v\"]]),\n",
    "                    )\n",
    "            # Eqn-3, second component\n",
    "            if len(graph[\"left\"][\"u\"] > 0):\n",
    "                temp.index_add_(\n",
    "                    0,\n",
    "                    graph[\"left\"][\"u\"],\n",
    "                    self.fuse[\"left\"][i](feat[graph[\"left\"][\"v\"]]),\n",
    "                )\n",
    "            if len(graph[\"right\"][\"u\"] > 0):\n",
    "                temp.index_add_(\n",
    "                    0,\n",
    "                    graph[\"right\"][\"u\"],\n",
    "                    self.fuse[\"right\"][i](feat[graph[\"right\"][\"v\"]]),\n",
    "                )\n",
    "\n",
    "            feat = self.fuse[\"norm\"][i](temp)\n",
    "            feat = self.relu(feat)\n",
    "\n",
    "            feat = self.fuse[\"ctr2\"][i](feat)\n",
    "            # Eqn-3, first component\n",
    "            feat += res\n",
    "            feat = self.relu(feat)\n",
    "            res = feat\n",
    "        return feat, graph[\"idcs\"], graph[\"ctrs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8513368",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_438620/3573889610.py:9: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  self.norm = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
      "/tmp/ipykernel_438620/3653812463.py:35: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  fuse[key].append(nn.GroupNorm(gcd(ng, n_map), n_map))\n"
     ]
    }
   ],
   "source": [
    "map_net = MapNet(config)\n",
    "nodes, node_idcs, node_ctrs = map_net(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c320df19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is nodes, node_idcs, node_ctrs?\n",
      "\n",
      "Feat:  torch.Size([2493, 128])\n",
      "[tensor([   0,    1,    2,  ..., 1014, 1015, 1016]), tensor([1017, 1018, 1019,  ..., 2490, 2491, 2492])]\n",
      "\n",
      "Node_ctrs:  torch.Size([1017, 2]) torch.Size([1476, 2])\n"
     ]
    }
   ],
   "source": [
    "print(\"What is nodes, node_idcs, node_ctrs?\")\n",
    "print(\"\\nFeat: \", nodes.shape)\n",
    "print(node_idcs)\n",
    "print(\"\\nNode_ctrs: \", node_ctrs[0].shape, node_ctrs[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9cd16d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl_venv",
   "language": "python",
   "name": "ssl_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

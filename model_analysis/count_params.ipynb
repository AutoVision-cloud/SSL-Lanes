{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2de382b",
   "metadata": {},
   "source": [
    "## DENSE-TNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6a946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    r\"\"\"\n",
    "    Layer normalization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, eps=1e-5):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.variance_epsilon = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = x.mean(-1, keepdim=True)\n",
    "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
    "        x = (x - u) / torch.sqrt(s + self.variance_epsilon)\n",
    "        return self.weight * x + self.bias\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden_size, out_features=None):\n",
    "        super(MLP, self).__init__()\n",
    "        if out_features is None:\n",
    "            out_features = hidden_size\n",
    "        self.linear = nn.Linear(hidden_size, out_features)\n",
    "        self.layer_norm = LayerNorm(out_features)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.linear(hidden_states)\n",
    "        hidden_states = self.layer_norm(hidden_states)\n",
    "        hidden_states = torch.nn.functional.relu(hidden_states)\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "class GlobalGraph(nn.Module):\n",
    "    r\"\"\"\n",
    "    Global graph\n",
    "    It's actually a self-attention.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, attention_head_size=None, num_attention_heads=1):\n",
    "        super(GlobalGraph, self).__init__()\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.attention_head_size = hidden_size // num_attention_heads if attention_head_size is None else attention_head_size\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "\n",
    "        self.num_qkv = 1\n",
    "\n",
    "        self.query = nn.Linear(hidden_size, self.all_head_size * self.num_qkv)\n",
    "        self.key = nn.Linear(hidden_size, self.all_head_size * self.num_qkv)\n",
    "        self.value = nn.Linear(hidden_size, self.all_head_size * self.num_qkv)\n",
    "        \n",
    "\n",
    "    def get_extended_attention_mask(self, attention_mask):\n",
    "        \"\"\"\n",
    "        1 in attention_mask stands for doing attention, 0 for not doing attention.\n",
    "        After this function, 1 turns to 0, 0 turns to -10000.0\n",
    "        Because the -10000.0 will be fed into softmax and -10000.0 can be thought as 0 in softmax.\n",
    "        \"\"\"\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1)\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "        return extended_attention_mask\n",
    "\n",
    "    def transpose_for_scores(self, x):\n",
    "        sz = x.size()[:-1] + (self.num_attention_heads,\n",
    "                              self.attention_head_size)\n",
    "        # (batch, max_vector_num, head, head_size)\n",
    "        x = x.view(*sz)\n",
    "        # (batch, head, max_vector_num, head_size)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask=None, mapping=None, return_scores=False):\n",
    "        mixed_query_layer = self.query(hidden_states)\n",
    "        mixed_key_layer = nn.functional.linear(hidden_states, self.key.weight)\n",
    "        mixed_value_layer = self.value(hidden_states)\n",
    "\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
    "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
    "\n",
    "        attention_scores = torch.matmul(\n",
    "            query_layer / math.sqrt(self.attention_head_size), key_layer.transpose(-1, -2))\n",
    "        # print(attention_scores.shape, attention_mask.shape)\n",
    "        if attention_mask is not None:\n",
    "            attention_scores = attention_scores + self.get_extended_attention_mask(attention_mask)\n",
    "        # if utils.args.attention_decay and utils.second_span:\n",
    "        #     attention_scores[:, 0, 0, 0] = attention_scores[:, 0, 0, 0] - self.attention_decay\n",
    "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
    "        \n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[\n",
    "                                  :-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "        if return_scores:\n",
    "            assert attention_probs.shape[1] == 1\n",
    "            attention_probs = torch.squeeze(attention_probs, dim=1)\n",
    "            assert len(attention_probs.shape) == 3\n",
    "            return context_layer, attention_probs\n",
    "        return context_layer\n",
    "\n",
    "\n",
    "class CrossAttention(GlobalGraph):\n",
    "    def __init__(self, hidden_size, attention_head_size=None, num_attention_heads=1, key_hidden_size=None,\n",
    "                 query_hidden_size=None):\n",
    "        super(CrossAttention, self).__init__(hidden_size, attention_head_size, num_attention_heads)\n",
    "        if query_hidden_size is not None:\n",
    "            self.query = nn.Linear(query_hidden_size, self.all_head_size * self.num_qkv)\n",
    "        if key_hidden_size is not None:\n",
    "            self.key = nn.Linear(key_hidden_size, self.all_head_size * self.num_qkv)\n",
    "            self.value = nn.Linear(key_hidden_size, self.all_head_size * self.num_qkv)\n",
    "\n",
    "    def forward(self, hidden_states_query, hidden_states_key=None, attention_mask=None, mapping=None,\n",
    "                return_scores=False):\n",
    "        mixed_query_layer = self.query(hidden_states_query)\n",
    "        mixed_key_layer = self.key(hidden_states_key)\n",
    "        mixed_value_layer = self.value(hidden_states_key)\n",
    "\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "        key_layer = self.transpose_for_scores(mixed_key_layer)\n",
    "        value_layer = self.transpose_for_scores(mixed_value_layer)\n",
    "\n",
    "        attention_scores = torch.matmul(\n",
    "            query_layer / math.sqrt(self.attention_head_size), key_layer.transpose(-1, -2))\n",
    "        if attention_mask is not None:\n",
    "            assert hidden_states_query.shape[1] == attention_mask.shape[1] \\\n",
    "                   and hidden_states_key.shape[1] == attention_mask.shape[2]\n",
    "            attention_scores = attention_scores + self.get_extended_attention_mask(attention_mask)\n",
    "        attention_probs = nn.Softmax(dim=-1)(attention_scores)\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[\n",
    "                                  :-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(*new_context_layer_shape)\n",
    "        if return_scores:\n",
    "            return context_layer, torch.squeeze(attention_probs, dim=1)\n",
    "        return context_layer\n",
    "\n",
    "\n",
    "class GlobalGraphRes(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(GlobalGraphRes, self).__init__()\n",
    "        self.global_graph = GlobalGraph(hidden_size, hidden_size // 2)\n",
    "        self.global_graph2 = GlobalGraph(hidden_size, hidden_size // 2)\n",
    "\n",
    "    def forward(self, hidden_states, attention_mask=None, mapping=None):\n",
    "        # hidden_states = self.global_graph(hidden_states, attention_mask, mapping) \\\n",
    "        #                 + self.global_graph2(hidden_states, attention_mask, mapping)\n",
    "        hidden_states = torch.cat([self.global_graph(hidden_states, attention_mask, mapping),\n",
    "                                   self.global_graph2(hidden_states, attention_mask, mapping)], dim=-1)\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "class PointSubGraph(nn.Module):\n",
    "    \"\"\"\n",
    "    Encode 2D goals conditioned on target agent\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size):\n",
    "        super(PointSubGraph, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layers = nn.ModuleList([MLP(2, hidden_size // 2),\n",
    "                                     MLP(hidden_size, hidden_size // 2),\n",
    "                                     MLP(hidden_size, hidden_size)])\n",
    "\n",
    "    def forward(self, hidden_states: Tensor, agent: Tensor):\n",
    "        device = hidden_states.device\n",
    "        predict_agent_num, point_num = hidden_states.shape[0], hidden_states.shape[1]\n",
    "        hidden_size = self.hidden_size\n",
    "        assert (agent.shape[0], agent.shape[1]) == (predict_agent_num, hidden_size)\n",
    "        agent = agent[:, :hidden_size // 2].unsqueeze(1).expand([predict_agent_num, point_num, hidden_size // 2])\n",
    "        for layer_index, layer in enumerate(self.layers):\n",
    "            if layer_index == 0:\n",
    "                hidden_states = layer(hidden_states)\n",
    "            else:\n",
    "                hidden_states = layer(torch.cat([hidden_states, agent], dim=-1))\n",
    "\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f840236",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import inspect\n",
    "import json\n",
    "import math\n",
    "import multiprocessing\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "import pdb\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Process\n",
    "from random import randint\n",
    "from typing import Dict, List, Tuple, NamedTuple, Any, Union, Optional\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def add_eval_param(param):\n",
    "    if param not in args.eval_params:\n",
    "        args.eval_params.append(param)\n",
    "\n",
    "\n",
    "def get_name(name='', append_time=False):\n",
    "    if name.endswith(time_begin):\n",
    "        return name\n",
    "    prefix = 'test.' if args.do_test else 'eval.' if args.do_eval and not args.do_train else ''\n",
    "    prefix = 'debug.' + prefix if args.debug else prefix\n",
    "    prefix = args.add_prefix + '.' + prefix if args.add_prefix is not None else prefix\n",
    "    suffix = '.' + time_begin if append_time else ''\n",
    "    return prefix + str(name) + suffix\n",
    "\n",
    "\n",
    "eps = 1e-5\n",
    "\n",
    "origin_point = None\n",
    "origin_angle = None\n",
    "\n",
    "\n",
    "def get_pad_vector(li):\n",
    "    \"\"\"\n",
    "    Pad vector to length of args.hidden_size\n",
    "    \"\"\"\n",
    "    assert len(li) <= args.hidden_size\n",
    "    li.extend([0] * (args.hidden_size - len(li)))\n",
    "    return li\n",
    "\n",
    "\n",
    "def batch_list_to_batch_tensors(batch):\n",
    "    return [each for each in batch]\n",
    "\n",
    "\n",
    "def batch_list_to_batch_tensors_old(batch):\n",
    "    batch_tensors = []\n",
    "    for x in zip(*batch):\n",
    "        batch_tensors.append(x)\n",
    "    return batch_tensors\n",
    "\n",
    "\n",
    "def round_value(v):\n",
    "    return round(v / 100)\n",
    "\n",
    "\n",
    "def get_dis(points: np.ndarray, point_label):\n",
    "    return np.sqrt(np.square((points[:, 0] - point_label[0])) + np.square((points[:, 1] - point_label[1])))\n",
    "\n",
    "\n",
    "def get_dis_point2point(point, point_=(0.0, 0.0)):\n",
    "    return np.sqrt(np.square((point[0] - point_[0])) + np.square((point[1] - point_[1])))\n",
    "\n",
    "\n",
    "def get_angle(x, y):\n",
    "    return math.atan2(y, x)\n",
    "\n",
    "\n",
    "def get_sub_matrix(traj, object_type, x=0, y=0, angle=None):\n",
    "    res = []\n",
    "    for i in range(0, len(traj), 2):\n",
    "        if i > 0:\n",
    "            vector = [traj[i - 2] - x, traj[i - 1] - y, traj[i] - x, traj[i + 1] - y]\n",
    "            if angle is not None:\n",
    "                vector[0], vector[1] = rotate(vector[0], vector[1], angle)\n",
    "                vector[2], vector[3] = rotate(vector[2], vector[3], angle)\n",
    "            res.append(vector)\n",
    "    return res\n",
    "\n",
    "\n",
    "def rotate(x, y, angle):\n",
    "    res_x = x * math.cos(angle) - y * math.sin(angle)\n",
    "    res_y = x * math.sin(angle) + y * math.cos(angle)\n",
    "    return res_x, res_y\n",
    "\n",
    "\n",
    "def rotate_(x, y, cos, sin):\n",
    "    res_x = x * cos - y * sin\n",
    "    res_y = x * sin + y * cos\n",
    "    return res_x, res_y\n",
    "\n",
    "\n",
    "index_file = 0\n",
    "\n",
    "file2pred = {}\n",
    "\n",
    "\n",
    "def __iter__(self):  # iterator to load data\n",
    "    for __ in range(math.ceil(len(self.ex_list) / float(self.batch_size))):\n",
    "        batch = []\n",
    "        for __ in range(self.batch_size):\n",
    "            idx = randint(0, len(self.ex_list) - 1)\n",
    "            batch.append(self.__getitem__(idx))\n",
    "        # To Tensor\n",
    "        yield batch_list_to_batch_tensors(batch)\n",
    "\n",
    "\n",
    "files_written = {}\n",
    "\n",
    "\n",
    "def logging(*inputs, prob=1.0, type='1', is_json=False, affi=True, sep=' ', to_screen=False, append_time=False, as_pickle=False):\n",
    "    \"\"\"\n",
    "    Print args into log file in a convenient style.\n",
    "    \"\"\"\n",
    "    if to_screen:\n",
    "        print(*inputs, sep=sep)\n",
    "    if not random.random() <= prob or not hasattr(args, 'log_dir'):\n",
    "        return\n",
    "\n",
    "    file = os.path.join(args.log_dir, get_name(type, append_time))\n",
    "    if as_pickle:\n",
    "        with open(file, 'wb') as pickle_file:\n",
    "            assert len(inputs) == 1\n",
    "            pickle.dump(*inputs, pickle_file)\n",
    "        return\n",
    "    if file not in files_written:\n",
    "        with open(file, \"w\", encoding='utf-8') as fout:\n",
    "            files_written[file] = 1\n",
    "    inputs = list(inputs)\n",
    "    the_tensor = None\n",
    "    for i, each in enumerate(inputs):\n",
    "        if isinstance(each, torch.Tensor):\n",
    "            # torch.Tensor(a), a must be Float tensor\n",
    "            if each.is_cuda:\n",
    "                each = each.cpu()\n",
    "            inputs[i] = each.data.numpy()\n",
    "            the_tensor = inputs[i]\n",
    "    np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "    with open(file, \"a\", encoding='utf-8') as fout:\n",
    "        if is_json:\n",
    "            for each in inputs:\n",
    "                print(json.dumps(each, indent=4), file=fout)\n",
    "        elif affi:\n",
    "            print(*tuple(inputs), file=fout, sep=sep)\n",
    "            if the_tensor is not None:\n",
    "                print(json.dumps(the_tensor.tolist()), file=fout)\n",
    "            print(file=fout)\n",
    "        else:\n",
    "            print(*tuple(inputs), file=fout, sep=sep)\n",
    "            print(file=fout)\n",
    "\n",
    "\n",
    "mpl.use('Agg')\n",
    "\n",
    "\n",
    "def larger(a, b):\n",
    "    return a > b + eps\n",
    "\n",
    "\n",
    "def equal(a, b):\n",
    "    return True if abs(a - b) < eps else False\n",
    "\n",
    "\n",
    "def get_valid_lens(matrix: np.ndarray):\n",
    "    valid_lens = []\n",
    "    for i in range(matrix.shape[0]):\n",
    "        ok = False\n",
    "        for j in range(2, matrix.shape[1], 2):\n",
    "            if equal(matrix[i][j], 0) and equal(matrix[i][j + 1], 0):\n",
    "                ok = True\n",
    "                valid_lens.append(j)\n",
    "                break\n",
    "\n",
    "        assert ok\n",
    "    return valid_lens\n",
    "\n",
    "\n",
    "visualize_num = 0\n",
    "\n",
    "\n",
    "def rot(verts, rad):\n",
    "    rad = -rad\n",
    "    verts = np.array(verts)\n",
    "    rotMat = np.array([[np.cos(rad), -np.sin(rad)], [np.sin(rad), np.cos(rad)]])\n",
    "    transVerts = verts.dot(rotMat)\n",
    "    return transVerts\n",
    "\n",
    "\n",
    "class CustomMarker(Path):\n",
    "    def __init__(self, icon, az):\n",
    "        import svgpath2mpl\n",
    "        # if icon == \"icon\":\n",
    "        #     verts = iconMat\n",
    "        # svg = \"\"\"<svg t=\"1624195118046\" class=\"icon\" viewBox=\"0 0 1024 1024\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" p-id=\"19465\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"700\" height=\"700\"><defs><style type=\"text/css\"></style></defs><path d=\"M812.875093 411.578027l-0.003413 0.01536-43.562667-11.671894V203.436373c0-102.367573-112.216747-185.35424-250.63936-185.35424s-250.641067 82.986667-250.641066 185.35424l-0.360107 10.238294v187.89376l-41.89696 11.226453-0.006827-0.01536c-26.519893 7.120213-44.946773 24.33536-41.166506 38.469973l47.930026-12.84096 0.003414 0.013654 35.136853-9.413974v484.061867l0.360107 7.022933c0 48.899413 112.218453 88.546987 250.641066 88.546987s250.63936-39.645867 250.63936-88.546987V427.36128l36.800854 9.86112 0.00512-0.01536 47.92832 12.84096c3.77856-14.134613-14.64832-31.34976-41.168214-38.469973zM658.152107 87.01952c13.34272-9.344 37.459627 2.075307 53.86752 25.506133s18.889387 49.998507 5.543253 59.342507c-13.34272 9.347413-37.46304-2.0736-53.86752-25.50272-16.406187-23.432533-18.891093-50.00192-5.543253-59.34592z m65.14176 231.66976l-42.922667 82.507093c-88.410453-28.182187-231.00416-29.134507-323.060053-2.84672l-41.96352-79.786666c92.73856-87.42912 315.33056-87.386453 407.94624 0.126293zM325.08416 111.418027c16.406187-23.430827 40.521387-34.850133 53.865813-25.506134 13.346133 9.344 10.862933 35.91168-5.543253 59.342507-16.402773 23.430827-40.521387 34.850133-53.865813 25.504427-13.34784-9.340587-10.86464-35.909973 5.543253-59.3408zM307.2 348.16c28.352853 17.481387 41.51808 150.084267 38.674773 276.48H307.2V348.16z m0 501.76V648.533333h37.94432c-3.43552 88.183467-14.849707 169.470293-34.530987 201.386667h-3.413333z m15.423147 21.143893l47.071573-118.454613 0.116053-0.114347c32.37888 32.37888 262.442667 30.34112 295.401814-2.618026l1.11104 0.269653 49.6896 117.439147c-43.892053 43.88864-350.266027 46.600533-393.39008 3.478186zM737.08032 846.506667h-3.413333c-19.679573-31.916373-31.095467-113.2032-34.52928-201.386667h37.942613v201.386667z m0-225.28h-38.673067c-2.843307-126.395733 10.320213-258.998613 38.673067-276.48v276.48z\" fill=\"#1296db\" p-id=\"19466\"></path></svg>\"\"\"\n",
    "        svg = \"M812.875093 411.578027l-0.003413 0.01536-43.562667-11.671894V203.436373c0-102.367573-112.216747-185.35424-250.63936-185.35424s-250.641067 82.986667-250.641066 185.35424l-0.360107 10.238294v187.89376l-41.89696 11.226453-0.006827-0.01536c-26.519893 7.120213-44.946773 24.33536-41.166506 38.469973l47.930026-12.84096 0.003414 0.013654 35.136853-9.413974v484.061867l0.360107 7.022933c0 48.899413 112.218453 88.546987 250.641066 88.546987s250.63936-39.645867 250.63936-88.546987V427.36128l36.800854 9.86112 0.00512-0.01536 47.92832 12.84096c3.77856-14.134613-14.64832-31.34976-41.168214-38.469973zM658.152107 87.01952c13.34272-9.344 37.459627 2.075307 53.86752 25.506133s18.889387 49.998507 5.543253 59.342507c-13.34272 9.347413-37.46304-2.0736-53.86752-25.50272-16.406187-23.432533-18.891093-50.00192-5.543253-59.34592z m65.14176 231.66976l-42.922667 82.507093c-88.410453-28.182187-231.00416-29.134507-323.060053-2.84672l-41.96352-79.786666c92.73856-87.42912 315.33056-87.386453 407.94624 0.126293zM325.08416 111.418027c16.406187-23.430827 40.521387-34.850133 53.865813-25.506134 13.346133 9.344 10.862933 35.91168-5.543253 59.342507-16.402773 23.430827-40.521387 34.850133-53.865813 25.504427-13.34784-9.340587-10.86464-35.909973 5.543253-59.3408zM307.2 348.16c28.352853 17.481387 41.51808 150.084267 38.674773 276.48H307.2V348.16z m0 501.76V648.533333h37.94432c-3.43552 88.183467-14.849707 169.470293-34.530987 201.386667h-3.413333z m15.423147 21.143893l47.071573-118.454613 0.116053-0.114347c32.37888 32.37888 262.442667 30.34112 295.401814-2.618026l1.11104 0.269653 49.6896 117.439147c-43.892053 43.88864-350.266027 46.600533-393.39008 3.478186zM737.08032 846.506667h-3.413333c-19.679573-31.916373-31.095467-113.2032-34.52928-201.386667h37.942613v201.386667z m0-225.28h-38.673067c-2.843307-126.395733 10.320213-258.998613 38.673067-276.48v276.48z\"\n",
    "        # import xml.etree.ElementTree as etree\n",
    "        # from six import StringIO\n",
    "        # tree = etree.parse(StringIO(svg))\n",
    "        # root = tree.getroot()\n",
    "        az = az + math.radians(180)\n",
    "        verts = svgpath2mpl.parse_path(svg).vertices\n",
    "        verts[:, 0] -= (867 - 180) / 2 + 180\n",
    "        verts[:, 1] -= (1008 - 18) / 2 + 18\n",
    "        vertices = rot(verts, az)\n",
    "        super().__init__(vertices, codes=svgpath2mpl.parse_path(svg).codes)\n",
    "\n",
    "\n",
    "def visualize_goals_2D(mapping, goals_2D, scores: np.ndarray, future_frame_num, loss=None, labels: np.ndarray = None,\n",
    "                       labels_is_valid=None, predict: np.ndarray = None):\n",
    "    print('in visualize_goals_2D', mapping['file_name'])\n",
    "    print('speed', mapping.get('seep', None))\n",
    "\n",
    "    assert predict is not None\n",
    "    predict = predict.reshape([6, future_frame_num, 2])\n",
    "    assert labels.shape == (future_frame_num, 2)\n",
    "\n",
    "    if 'eval_time' in mapping:\n",
    "        assert labels.shape[0] == labels_is_valid.shape[0] == future_frame_num\n",
    "        eval_time = mapping['eval_time']\n",
    "        labels = labels[:eval_time]\n",
    "        predict = predict[:, :eval_time, :]\n",
    "        labels_is_valid = labels_is_valid[:eval_time]\n",
    "        future_frame_num = eval_time\n",
    "\n",
    "    if labels_is_valid is not None:\n",
    "        assert labels.shape[0] == labels_is_valid.shape[0]\n",
    "        labels = [labels[i] for i in range(future_frame_num) if labels_is_valid[i]]\n",
    "        labels = np.array(labels)\n",
    "\n",
    "    if 'time_offset' in mapping:\n",
    "        time_offset = mapping['time_offset']\n",
    "    else:\n",
    "        time_offset = None\n",
    "\n",
    "    assert labels is not None\n",
    "    labels = labels.reshape([-1])\n",
    "\n",
    "    fig_scale = 1.0\n",
    "    marker_size_scale = 2\n",
    "    # target_agent_color, target_agent_edge_color = '#0d79e7', '#bcd6ed' # blue\n",
    "    target_agent_color, target_agent_edge_color = '#4bad34', '#c5dfb3'\n",
    "\n",
    "    def get_scaled_int(a):\n",
    "        return round(a * fig_scale)\n",
    "\n",
    "    plt.cla()\n",
    "    fig = plt.figure(0, figsize=(get_scaled_int(45), get_scaled_int(38)))\n",
    "\n",
    "    if True:\n",
    "        plt.xlim(-100, 100)\n",
    "        plt.ylim(-30, 100)\n",
    "\n",
    "    # plt.figure(0, dpi=300)\n",
    "    cmap = plt.cm.get_cmap('Reds')\n",
    "    vmin = np.log(0.0001)\n",
    "    vmin = np.log(0.00001)\n",
    "    scores = np.clip(scores.copy(), a_min=vmin, a_max=np.inf)\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin, vmax=np.max(scores)))\n",
    "    plt.colorbar(sm)\n",
    "\n",
    "    trajs = mapping['trajs']\n",
    "    if args.argoverse:\n",
    "        name = os.path.split(mapping['file_name'])[1].split('.')[0]\n",
    "    name = name + '.FDE={}'.format(loss)\n",
    "\n",
    "    add_end = True\n",
    "\n",
    "    linewidth = 5\n",
    "\n",
    "    for lane in mapping['vis_lanes']:\n",
    "        lane = lane[:, :2]\n",
    "        assert lane.shape == (len(lane), 2), lane.shape\n",
    "        plt.plot(lane[:, 0], lane[:, 1], linestyle=\"-\", color=\"black\", marker=None,\n",
    "                 markersize=0,\n",
    "                 alpha=0.5,\n",
    "                 linewidth=2,\n",
    "                 zorder=0)\n",
    "        # plt.fill(lane[:, 0], lane[:, 1], linestyle=\"-\", color='#a5a5a5',\n",
    "        #          linewidth=2,\n",
    "        #          zorder=0)\n",
    "\n",
    "    yaw_0 = None\n",
    "\n",
    "    def draw_his_trajs():\n",
    "        for i, traj in enumerate(trajs):\n",
    "            assert isinstance(traj, np.ndarray)\n",
    "            assert traj.ndim == 2 and traj.shape[1] == 2, traj.shape\n",
    "            if i == 0:\n",
    "                traj = np.array(traj).reshape([-1])\n",
    "                t = np.zeros(len(traj) + 2)\n",
    "                t[:len((traj))] = traj\n",
    "                t[-2] = labels[0]\n",
    "                t[-1] = labels[1]\n",
    "\n",
    "                plt.plot(t[0::2], t[1::2], linestyle=\"-\", color=target_agent_color, marker=None,\n",
    "                         alpha=1,\n",
    "                         linewidth=linewidth,\n",
    "                         zorder=0)\n",
    "                # if 'vis_video' in args.other_params:\n",
    "                # plt.plot(0.0, 0.0, marker=CustomMarker(\"icon\", 0), c=target_agent_color,\n",
    "                #          markersize=20 * marker_size_scale, markeredgecolor=target_agent_edge_color, markeredgewidth=0.5)\n",
    "            else:\n",
    "                if True:\n",
    "                    pass\n",
    "                else:\n",
    "                    if len(traj) >= 2:\n",
    "                        color = \"darkblue\"\n",
    "                        plt.plot(traj[:, 0], traj[:, 1], linestyle=\"-\", color=color, marker=None,\n",
    "                                 alpha=1,\n",
    "                                 linewidth=linewidth,\n",
    "                                 zorder=0)\n",
    "\n",
    "    draw_his_trajs()\n",
    "\n",
    "    if True:\n",
    "        if goals_2D is not None:\n",
    "            goals_2D = np.array(goals_2D)\n",
    "            marker_size = 70\n",
    "            plt.scatter(goals_2D[:, 0], goals_2D[:, 1], c=scores, cmap=cmap, norm=sm.norm, s=marker_size, alpha=0.5, marker=',')\n",
    "        # s is size, default 20\n",
    "\n",
    "        # if False:\n",
    "        for each in predict:\n",
    "            function2 = plt.plot(each[:, 0], each[:, 1], linestyle=\"-\", color=\"darkorange\", marker=None,\n",
    "                                 linewidth=linewidth,\n",
    "                                 zorder=0, label='Predicted trajectory')\n",
    "\n",
    "            if add_end:\n",
    "                plt.plot(each[-1, 0], each[-1, 1], markersize=15 * marker_size_scale, color=\"darkorange\", marker=\"*\",\n",
    "                         markeredgecolor='black')\n",
    "\n",
    "        if add_end:\n",
    "            plt.plot(labels[-2], labels[-1], markersize=15 * marker_size_scale, color=target_agent_color, marker=\"*\",\n",
    "                     markeredgecolor='black')\n",
    "\n",
    "        function1 = plt.plot(labels[0::2], labels[1::2], linestyle=\"-\", color=target_agent_color, linewidth=linewidth,\n",
    "                             zorder=0, label='Ground truth trajectory')\n",
    "\n",
    "    functions = function1 + function2\n",
    "    fun_labels = [f.get_label() for f in functions]\n",
    "    plt.legend(functions, fun_labels, loc=0)\n",
    "\n",
    "    plt.title('FDE={} file_name={}'.format(loss, mapping['file_name']))\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect(1)\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(4))\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(4))\n",
    "\n",
    "    os.makedirs(os.path.join(args.log_dir, 'visualize_' + time_begin), exist_ok=True)\n",
    "    plt.savefig(os.path.join(args.log_dir, 'visualize_' + time_begin,\n",
    "                             get_name(\"visualize\" + (\"\" if name == \"\" else \"_\" + name) + \".png\")), bbox_inches='tight')\n",
    "    plt.close()\n",
    "    global visualize_num\n",
    "    visualize_num += 1\n",
    "    if visualize_num > 200 and 'vis_video' not in args.other_params and 'vis_all' not in args.other_params:\n",
    "        print('press any key to continue')\n",
    "        input()\n",
    "\n",
    "\n",
    "def load_model(model, state_dict, prefix=''):\n",
    "    missing_keys = []\n",
    "    unexpected_keys = []\n",
    "    error_msgs = []\n",
    "    # copy state_dict so _load_from_state_dict can modify it\n",
    "    metadata = getattr(state_dict, '_metadata', None)\n",
    "    state_dict = state_dict.copy()\n",
    "    if metadata is not None:\n",
    "        state_dict._metadata = metadata\n",
    "\n",
    "    def load(module, prefix=''):\n",
    "        local_metadata = {} if metadata is None else metadata.get(\n",
    "            prefix[:-1], {})\n",
    "        module._load_from_state_dict(\n",
    "            state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)\n",
    "        for name, child in module._modules.items():\n",
    "            if child is not None:\n",
    "                load(child, prefix + name + '.')\n",
    "\n",
    "    load(model, prefix)\n",
    "\n",
    "    if logger is None:\n",
    "        return\n",
    "\n",
    "    if len(missing_keys) > 0:\n",
    "        print(\"Weights of {} not initialized from pretrained model: {}\".format(\n",
    "            model.__class__.__name__, json.dumps(missing_keys, indent=4)))\n",
    "    if len(unexpected_keys) > 0:\n",
    "        print(\"Weights from pretrained model not used in {}: {}\".format(\n",
    "            model.__class__.__name__, json.dumps(unexpected_keys, indent=4)))\n",
    "    if len(error_msgs) > 0:\n",
    "        print('\\n'.join(error_msgs))\n",
    "\n",
    "\n",
    "traj_last = None\n",
    "\n",
    "\n",
    "def batch_init(mapping):\n",
    "    global traj_last, origin_point, origin_angle\n",
    "    batch_size = len(mapping)\n",
    "\n",
    "    global origin_point, origin_angle\n",
    "    origin_point = np.zeros([batch_size, 2])\n",
    "    origin_angle = np.zeros([batch_size])\n",
    "    for i in range(batch_size):\n",
    "        origin_point[i][0], origin_point[i][1] = rotate(0 - mapping[i]['cent_x'], 0 - mapping[i]['cent_y'],\n",
    "                                                        mapping[i]['angle'])\n",
    "        origin_angle[i] = -mapping[i]['angle']\n",
    "\n",
    "    def load_file2pred():\n",
    "        global file2pred\n",
    "        if len(file2pred) == 0:\n",
    "            with open(args.other_params['set_predict_file2pred'], 'rb') as pickle_file:\n",
    "                file2pred = pickle.load(pickle_file)\n",
    "\n",
    "\n",
    "second_span = False\n",
    "\n",
    "li_vector_num = None\n",
    "\n",
    "\n",
    "def turn_traj(traj: np.ndarray, object_type='AGENT'):\n",
    "    vectors = []\n",
    "    traj = traj.reshape([-1, 2])\n",
    "    for i, point in enumerate(traj):\n",
    "        x, y = point[0], point[1]\n",
    "        if i > 0:\n",
    "            vector = [point_pre[0], point_pre[1], x, y, i * 0.1, object_type == 'AV',\n",
    "                      object_type == 'AGENT', object_type == 'OTHERS', 0, i]\n",
    "            vectors.append(get_pad_vector(vector))\n",
    "        point_pre = point\n",
    "    return vectors\n",
    "\n",
    "\n",
    "def merge_tensors(tensors: List[torch.Tensor], device, hidden_size=None) -> Tuple[Tensor, List[int]]:\n",
    "    \"\"\"\n",
    "    merge a list of tensors into a tensor\n",
    "    \"\"\"\n",
    "    lengths = []\n",
    "    hidden_size = args.hidden_size if hidden_size is None else hidden_size\n",
    "    for tensor in tensors:\n",
    "        lengths.append(tensor.shape[0] if tensor is not None else 0)\n",
    "    res = torch.zeros([len(tensors), max(lengths), hidden_size], device=device)\n",
    "    for i, tensor in enumerate(tensors):\n",
    "        if tensor is not None:\n",
    "            res[i][:tensor.shape[0]] = tensor\n",
    "    return res, lengths\n",
    "\n",
    "\n",
    "def de_merge_tensors(tensor: Tensor, lengths):\n",
    "    return [tensor[i, :lengths[i]] for i in range(len(lengths))]\n",
    "\n",
    "\n",
    "def gather_tensors(tensor: torch.Tensor, indices: List[list]):\n",
    "    lengths = [len(each) for each in indices]\n",
    "    assert tensor.shape[0] == len(indices)\n",
    "    for each in indices:\n",
    "        each.extend([0] * (tensor.shape[1] - len(each)))\n",
    "    index = torch.tensor(indices, device=tensor.device)\n",
    "    index = index.unsqueeze(2).expand(tensor.shape)\n",
    "    tensor = torch.gather(tensor, 1, index)\n",
    "    for i, length in enumerate(lengths):\n",
    "        tensor[i, length:, :].fill_(0)\n",
    "    # index = torch.zeros(tensor.shape, device=tensor.device, dtype=torch.int)\n",
    "    return tensor, lengths\n",
    "\n",
    "\n",
    "def get_closest_polygon(pred: np.ndarray, new_polygons) -> np.ndarray:\n",
    "    dis = np.inf\n",
    "    closest_polygon = None\n",
    "\n",
    "    def get_dis(pred: np.ndarray, polygon):\n",
    "        dis = 0\n",
    "        pred = pred.reshape([30, 2])\n",
    "        for point in pred:\n",
    "            dis += np.min(np.abs(polygon[:, 0] - point[0]) + np.abs(polygon[:, 1] - point[1]))\n",
    "        return dis\n",
    "\n",
    "    for idx_polygon, polygon in enumerate(new_polygons):\n",
    "        temp = get_dis(pred, polygon)\n",
    "        if temp < dis:\n",
    "            dis = temp\n",
    "            closest_polygon = polygon\n",
    "    return closest_polygon\n",
    "\n",
    "\n",
    "NMS_LIST = [2.0, 1.7, 1.4, 2.3, 2.6] + [2.9, 3.2, 3.5, 3.8, 4.1] + [2.7, 2.8, 3.0, 3.1]\n",
    "\n",
    "NMS_START = 6\n",
    "\n",
    "DYNAMIC_NMS_START = 30\n",
    "\n",
    "DYNAMIC_NMS_LIST = [3.2, 3.8, 4.8, 5.4, 6.0] + [6.6, 7.2, 7.8, 8.4, 0.0] + \\\n",
    "                   [2.0, 2.6, 1.5, 0.1]\n",
    "\n",
    "\n",
    "def select_goals_by_NMS(mapping: Dict, goals_2D: np.ndarray, scores: np.ndarray, threshold, speed, gt_goal=None, mode_num=6):\n",
    "    argsort = np.argsort(-scores)\n",
    "    goals_2D = goals_2D[argsort]\n",
    "    scores = scores[argsort]\n",
    "\n",
    "    add_eval_param(f'DY_NMS={threshold}')\n",
    "\n",
    "    speed_scale_factor = 1#utils_cython.speed_scale_factor(speed)\n",
    "    threshold = threshold * speed_scale_factor\n",
    "\n",
    "    pred_goals = []\n",
    "    pred_probs = []\n",
    "\n",
    "    def in_predict(pred_goals, point, threshold):\n",
    "        return np.min(get_dis_point_2_points(point, pred_goals)) < threshold\n",
    "\n",
    "    for i in range(len(goals_2D)):\n",
    "        if len(pred_goals) > 0 and in_predict(np.array(pred_goals), goals_2D[i], threshold):\n",
    "            continue\n",
    "        else:\n",
    "            pred_goals.append(goals_2D[i])\n",
    "            pred_probs.append(scores[i])\n",
    "            if len(pred_goals) == mode_num:\n",
    "                break\n",
    "\n",
    "    while len(pred_goals) < mode_num:\n",
    "        i = np.random.randint(0, len(goals_2D))\n",
    "        pred_goals.append(goals_2D[i])\n",
    "        pred_probs.append(scores[i])\n",
    "\n",
    "    pred_goals = np.array(pred_goals)\n",
    "    pred_probs = np.array(pred_probs)\n",
    "\n",
    "    FDE = np.inf\n",
    "    if gt_goal is not None:\n",
    "        for each in pred_goals:\n",
    "            FDE = min(FDE, get_dis_point2point(each, gt_goal))\n",
    "\n",
    "    mapping['pred_goals'] = pred_goals\n",
    "    mapping['pred_probs'] = pred_probs\n",
    "\n",
    "\n",
    "def select_goal_pairs_by_NMS(mapping: Dict, mapping_oppo: Dict, goals_4D: np.ndarray, scores_4D: np.ndarray, threshold, speed, speed_oppo,\n",
    "                             mode_num=6):\n",
    "    argsort = np.argsort(-scores_4D)\n",
    "\n",
    "    goals_4D = goals_4D[argsort]\n",
    "    scores_4D = scores_4D[argsort]\n",
    "\n",
    "    def in_predict(pred_goal_pairs, goal_pair, thresholds):\n",
    "        # pred_goal_pairs [..., 2, 2]\n",
    "        return np.min(get_dis_point_2_points(goal_pair[0], pred_goal_pairs[:, 0, :])) < thresholds[0] \\\n",
    "               and np.min(get_dis_point_2_points(goal_pair[1], pred_goal_pairs[:, 1, :])) < thresholds[1]\n",
    "\n",
    "    add_eval_param(f'DY_NMS={threshold}')\n",
    "\n",
    "    thresholds = (threshold * utils_cython.speed_scale_factor(speed), threshold * utils_cython.speed_scale_factor(speed_oppo))\n",
    "\n",
    "    pred_goal_pairs = []\n",
    "    pred_probs = []\n",
    "\n",
    "    for i in range(len(goals_4D)):\n",
    "        if len(pred_goal_pairs) > 0 and in_predict(np.array(pred_goal_pairs), goals_4D[i].reshape((2, 2)), thresholds):\n",
    "            continue\n",
    "        else:\n",
    "            pred_goal_pairs.append(goals_4D[i].reshape((2, 2)))\n",
    "            pred_probs.append(scores_4D[i])\n",
    "            if len(pred_goal_pairs) == mode_num:\n",
    "                break\n",
    "\n",
    "    while len(pred_goal_pairs) < mode_num:\n",
    "        i = np.random.randint(0, len(pred_goal_pairs))\n",
    "        pred_goal_pairs.append(goals_4D[i].reshape((2, 2)))\n",
    "        pred_probs.append(scores_4D[i])\n",
    "\n",
    "    pred_goal_pairs = np.array(pred_goal_pairs)\n",
    "    pred_probs = np.array(pred_probs)\n",
    "\n",
    "    mapping['pred_goals'] = pred_goal_pairs[:, 0, :]\n",
    "    mapping['pred_probs'] = pred_probs\n",
    "    mapping_oppo['pred_goals'] = pred_goal_pairs[:, 1, :]\n",
    "    mapping_oppo['pred_probs'] = pred_probs\n",
    "\n",
    "\n",
    "def get_FDE(points: np.ndarray, scores: np.ndarray, mapping, gt_goal=None, method=0, idx_in_batch=0, mode_num=6):\n",
    "    points = points.copy()\n",
    "    scores = scores.copy()\n",
    "    polygons = mapping['polygons']\n",
    "\n",
    "    li = sorted([(point, score) for (point, score) in zip(points, scores)], key=lambda x: x[1], reverse=True)\n",
    "    points = np.array([each[0] for each in li])\n",
    "    if 'scale' in mapping:\n",
    "        scale = mapping['scale']\n",
    "        points *= 1.0 / scale\n",
    "\n",
    "    scores = np.array([each[1] for each in li])\n",
    "\n",
    "    def get_hash(point):\n",
    "        return round((point[0] + 500) * 100) * 1000000 + round((point[1] + 500) * 100)\n",
    "\n",
    "    if True:\n",
    "        scores = np.exp(scores)\n",
    "\n",
    "        def get_scaled_scores(scores, sum=1.0):\n",
    "            sum_cur = np.sum(scores)\n",
    "            scores = scores / sum_cur * sum\n",
    "            return scores\n",
    "\n",
    "        if method == 1:\n",
    "            idx = np.searchsorted(-scores, -0.001, side='right')\n",
    "            scores, points = scores[:idx], points[:idx]\n",
    "\n",
    "            def fn(a):\n",
    "                return a + a ** 1.2\n",
    "\n",
    "            scaled_scores = scores.copy()\n",
    "            for i in range(len(scores)):\n",
    "                scaled_scores[i] = fn(scaled_scores[i])\n",
    "            scaled_scores = get_scaled_scores(scaled_scores, np.sum(scores))\n",
    "            # for a, b in zip(scores, scaled_scores):\n",
    "            #     print(a, b)\n",
    "            scores = scaled_scores\n",
    "\n",
    "        elif method == 2:\n",
    "            idx = np.searchsorted(-scores, -0.001, side='right')\n",
    "            scores, points = scores[:idx], points[:idx]\n",
    "\n",
    "            def fn(a):\n",
    "                return a + a ** 0.9\n",
    "\n",
    "            scaled_scores = scores.copy()\n",
    "            for i in range(len(scores)):\n",
    "                scaled_scores[i] = fn(scaled_scores[i])\n",
    "            scaled_scores = get_scaled_scores(scaled_scores, np.sum(scores))\n",
    "            # for a, b in zip(scores, scaled_scores):\n",
    "            #     print(a, b)\n",
    "            scores = scaled_scores\n",
    "        elif method == 3:\n",
    "            idx = np.searchsorted(-scores, -0.001, side='right')\n",
    "            scores, points = scores[:idx], points[:idx]\n",
    "\n",
    "            def fn(a):\n",
    "                return a + a ** 1.1\n",
    "\n",
    "            scaled_scores = scores.copy()\n",
    "            for i in range(len(scores)):\n",
    "                scaled_scores[i] = fn(scaled_scores[i])\n",
    "            scaled_scores = get_scaled_scores(scaled_scores, np.sum(scores))\n",
    "            # for a, b in zip(scores, scaled_scores):\n",
    "            #     print(a, b)\n",
    "            scores = scaled_scores\n",
    "        elif method == 4:\n",
    "            idx = np.searchsorted(-scores, -0.001, side='right')\n",
    "            scores, points = scores[:idx], points[:idx]\n",
    "\n",
    "            def fn(a):\n",
    "                return a + a ** 0.8\n",
    "\n",
    "            scaled_scores = scores.copy()\n",
    "            for i in range(len(scores)):\n",
    "                scaled_scores[i] = fn(scaled_scores[i])\n",
    "            scaled_scores = get_scaled_scores(scaled_scores, np.sum(scores))\n",
    "            # for a, b in zip(scores, scaled_scores):\n",
    "            #     print(a, b)\n",
    "            scores = scaled_scores\n",
    "        elif method == 5:\n",
    "            idx = np.searchsorted(-scores, -0.001, side='right')\n",
    "            scores, points = scores[:idx], points[:idx]\n",
    "\n",
    "            def fn(a):\n",
    "                return a + a ** 0.7\n",
    "\n",
    "            scaled_scores = scores.copy()\n",
    "            for i in range(len(scores)):\n",
    "                scaled_scores[i] = fn(scaled_scores[i])\n",
    "            scaled_scores = get_scaled_scores(scaled_scores, np.sum(scores))\n",
    "            # print()\n",
    "            # for a, b in zip(scores, scaled_scores):\n",
    "            #     print(str(a)[:6], str(b)[:6])\n",
    "            scores = scaled_scores\n",
    "        elif NMS_START <= method < NMS_START + len(NMS_LIST):\n",
    "            threshold = NMS_LIST[method - NMS_START]\n",
    "            add_eval_param(f'NMS={threshold}')\n",
    "            # print('threshold', threshold)\n",
    "            predict = []\n",
    "            ans_point_scores = []\n",
    "\n",
    "            def in_predict(predict, point, threshold):\n",
    "                return np.min(get_dis_point_2_points(point, predict)) < threshold\n",
    "\n",
    "            for i in range(len(points)):\n",
    "                if len(predict) > 0 and in_predict(np.array(predict), points[i], threshold):\n",
    "                    continue\n",
    "                else:\n",
    "                    predict.append(points[i])\n",
    "                    ans_point_scores.append(scores[i])\n",
    "                    if len(predict) == mode_num:\n",
    "                        break\n",
    "            while len(predict) < mode_num:\n",
    "                i = np.random.randint(0, len(points))\n",
    "                predict.append(points[i])\n",
    "                ans_point_scores.append(scores[i])\n",
    "\n",
    "            idx_in_batch_2_ans_points[idx_in_batch] = np.array(predict)\n",
    "            idx_in_batch_2_ans_point_scores[idx_in_batch] = np.array(ans_point_scores)\n",
    "            FDE = np.inf\n",
    "            if gt_goal is not None:\n",
    "                for each in predict:\n",
    "                    FDE = min(FDE, get_dis_point2point(each, gt_goal))\n",
    "            method2FDEs[method].append(FDE)\n",
    "        elif DYNAMIC_NMS_START <= method < DYNAMIC_NMS_START + len(DYNAMIC_NMS_LIST):\n",
    "            threshold = DYNAMIC_NMS_LIST[method - DYNAMIC_NMS_START]\n",
    "            add_eval_param(f'DY_NMS={threshold}')\n",
    "            speed_scale_factor = utils_cython.speed_scale_factor(mapping['speed'])\n",
    "            threshold = threshold * speed_scale_factor\n",
    "\n",
    "            # print('threshold', threshold)\n",
    "            predict = []\n",
    "            ans_point_scores = []\n",
    "\n",
    "            def in_predict(predict, point, threshold):\n",
    "                return np.min(get_dis_point_2_points(point, predict)) < threshold\n",
    "\n",
    "            for i in range(len(points)):\n",
    "                if len(predict) > 0 and in_predict(np.array(predict), points[i], threshold):\n",
    "                    continue\n",
    "                else:\n",
    "                    predict.append(points[i])\n",
    "                    ans_point_scores.append(scores[i])\n",
    "                    if len(predict) == mode_num:\n",
    "                        break\n",
    "            while len(predict) < mode_num:\n",
    "                i = np.random.randint(0, len(points))\n",
    "                predict.append(points[i])\n",
    "                ans_point_scores.append(scores[i])\n",
    "\n",
    "            idx_in_batch_2_ans_points[idx_in_batch] = np.array(predict)\n",
    "            idx_in_batch_2_ans_point_scores[idx_in_batch] = np.array(ans_point_scores)\n",
    "            FDE = np.inf\n",
    "            if gt_goal is not None:\n",
    "                for each in predict:\n",
    "                    FDE = min(FDE, get_dis_point2point(each, gt_goal))\n",
    "            method2FDEs[method].append(FDE)\n",
    "            pass\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "        if method < 6:\n",
    "            # Note 'method > 0' in train.py\n",
    "            with open(os.path.join(args.temp_file_dir, time_begin, \"cpp_input\" + str(idx_in_batch)), \"w\") as fout:\n",
    "                print(len(points), file=fout)\n",
    "                for point, score in zip(points, scores):\n",
    "                    print(point[0], point[1], score, file=fout)\n",
    "\n",
    "\n",
    "def get_subdivide_points(polygon, include_self=False, threshold=1.0, include_beside=False, return_unit_vectors=False):\n",
    "    def get_dis(point_a, point_b):\n",
    "        return np.sqrt((point_a[0] - point_b[0]) ** 2 + (point_a[1] - point_b[1]) ** 2)\n",
    "\n",
    "    average_dis = 0\n",
    "    for i, point in enumerate(polygon):\n",
    "        if i > 0:\n",
    "            average_dis += get_dis(point, point_pre)\n",
    "        point_pre = point\n",
    "    average_dis /= len(polygon) - 1\n",
    "\n",
    "    points = []\n",
    "    if return_unit_vectors:\n",
    "        assert not include_self and not include_beside\n",
    "        unit_vectors = []\n",
    "    divide_num = 1\n",
    "    while average_dis / divide_num > threshold:\n",
    "        divide_num += 1\n",
    "    for i, point in enumerate(polygon):\n",
    "        if i > 0:\n",
    "            for k in range(1, divide_num):\n",
    "                def get_kth_point(point_a, point_b, ratio):\n",
    "                    return (point_a[0] * (1 - ratio) + point_b[0] * ratio,\n",
    "                            point_a[1] * (1 - ratio) + point_b[1] * ratio)\n",
    "\n",
    "                points.append(get_kth_point(point_pre, point, k / divide_num))\n",
    "                if return_unit_vectors:\n",
    "                    unit_vectors.append(get_unit_vector(point_pre, point))\n",
    "        if include_self or include_beside:\n",
    "            points.append(point)\n",
    "        point_pre = point\n",
    "    if include_beside:\n",
    "        points_ = []\n",
    "        for i, point in enumerate(points):\n",
    "            if i > 0:\n",
    "                der_x = point[0] - point_pre[0]\n",
    "                der_y = point[1] - point_pre[1]\n",
    "                scale = 1 / math.sqrt(der_x ** 2 + der_y ** 2)\n",
    "                der_x *= scale\n",
    "                der_y *= scale\n",
    "                der_x, der_y = rotate(der_x, der_y, math.pi / 2)\n",
    "                for k in range(-2, 3):\n",
    "                    if k != 0:\n",
    "                        points_.append((point[0] + k * der_x, point[1] + k * der_y))\n",
    "                        if i == 1:\n",
    "                            points_.append((point_pre[0] + k * der_x, point_pre[1] + k * der_y))\n",
    "            point_pre = point\n",
    "        points.extend(points_)\n",
    "    if return_unit_vectors:\n",
    "        return points, unit_vectors\n",
    "    return points\n",
    "    # return points if not return_unit_vectors else points, unit_vectors\n",
    "\n",
    "\n",
    "def get_one_subdivide_polygon(polygon):\n",
    "    new_polygon = []\n",
    "    for i, point in enumerate(polygon):\n",
    "        if i > 0:\n",
    "            new_polygon.append((polygon[i - 1] + polygon[i]) / 2)\n",
    "        new_polygon.append(point)\n",
    "    return new_polygon\n",
    "\n",
    "\n",
    "def get_subdivide_polygons(polygon, threshold=2.0):\n",
    "    if len(polygon) == 1:\n",
    "        polygon = [polygon[0], polygon[0]]\n",
    "    elif len(polygon) % 2 == 1:\n",
    "        polygon = list(polygon)\n",
    "        polygon = polygon[:len(polygon) // 2] + polygon[-(len(polygon) // 2):]\n",
    "    assert_(len(polygon) >= 2)\n",
    "\n",
    "    def get_dis(point_a, point_b):\n",
    "        return np.sqrt((point_a[0] - point_b[0]) ** 2 + (point_a[1] - point_b[1]) ** 2)\n",
    "\n",
    "    def get_average_dis(polygon):\n",
    "        average_dis = 0\n",
    "        for i, point in enumerate(polygon):\n",
    "            if i > 0:\n",
    "                average_dis += get_dis(point, point_pre)\n",
    "            point_pre = point\n",
    "        average_dis /= len(polygon) - 1\n",
    "        return average_dis\n",
    "\n",
    "    average_dis = get_average_dis(polygon)\n",
    "\n",
    "    if average_dis > threshold:\n",
    "        length = len(polygon)\n",
    "        point_a = polygon[length // 2 - 1]\n",
    "        point_b = polygon[length // 2]\n",
    "        point_mid = (point_a + point_b) / 2\n",
    "        polygon_a = polygon[:length // 2]\n",
    "        polygon_a = get_one_subdivide_polygon(polygon_a)\n",
    "        polygon_a = polygon_a + [point_mid]\n",
    "        polygon_b = polygon[length // 2:]\n",
    "        polygon_b = get_one_subdivide_polygon(polygon_b)\n",
    "        polygon_b = [point_mid] + polygon_b\n",
    "        assert_(len(polygon) == len(polygon_a))\n",
    "        # print('polygon', np.array(polygon), 'polygon_a',np.array(polygon_a), average_dis, get_average_dis(polygon_a))\n",
    "        return get_subdivide_polygons(polygon_a) + get_subdivide_polygons(polygon_b)\n",
    "    else:\n",
    "        return [polygon]\n",
    "\n",
    "\n",
    "method2FDEs = defaultdict(list)\n",
    "\n",
    "\n",
    "def get_neighbour_points(points, topk_ids=None, mapping=None, neighbour_dis=2):\n",
    "    # grid = np.zeros([300, 300], dtype=int)\n",
    "    grid = {}\n",
    "    for fake_idx, point in enumerate(points):\n",
    "        x, y = round(float(point[0])), round(float(point[1]))\n",
    "\n",
    "        # not compatible argo\n",
    "        for i in range(-neighbour_dis, neighbour_dis + 1):\n",
    "            for j in range(-neighbour_dis, neighbour_dis + 1):\n",
    "                grid[(x + i, y + j)] = 1\n",
    "    points = list(grid.keys())\n",
    "    return points\n",
    "\n",
    "\n",
    "def get_neighbour_points_new(points, neighbour_dis=2, density=1.0):\n",
    "    grid = {}\n",
    "\n",
    "    for fake_idx, point in enumerate(points):\n",
    "        x, y = round(float(point[0])), round(float(point[1]))\n",
    "        if -100 <= x <= 100 and -100 <= y <= 100:\n",
    "            i = x - neighbour_dis\n",
    "            while i < x + neighbour_dis + eps:\n",
    "                j = y - neighbour_dis\n",
    "                while j < y + neighbour_dis + eps:\n",
    "                    grid[(i, j)] = True\n",
    "                    j += density\n",
    "                i += density\n",
    "    points = list(grid.keys())\n",
    "    points = get_points_remove_repeated(points, density)\n",
    "    return points\n",
    "\n",
    "\n",
    "def get_neighbour_points_for_lanes(polygons):\n",
    "    points = []\n",
    "    for polygon in polygons:\n",
    "        points.extend(polygon)\n",
    "    return get_neighbour_points(points)\n",
    "\n",
    "\n",
    "def calc_bitmap(bitmap, polygon):\n",
    "    for point_idx, point in enumerate(polygon):\n",
    "        if point_idx > 0:\n",
    "            walk_bitmap(bitmap, point_pre, point, calc_bitmap=True)\n",
    "        point_pre = point\n",
    "    pass\n",
    "\n",
    "\n",
    "def walk_bitmap(bitmap, point_a, point_b, calc_bitmap=False, check_bitmap=False):\n",
    "    point_a = (round(float(point_a[0])) + 150, round(float(point_a[1])) + 150)\n",
    "    point_b = (round(float(point_b[0])) + 150, round(float(point_b[1])) + 150)\n",
    "    xs = [0, 0, 1, -1]\n",
    "    ys = [1, -1, 0, 0]\n",
    "    while True:\n",
    "        if 0 <= point_a[0] < 300 and 0 <= point_a[1] < 300:\n",
    "            if calc_bitmap:\n",
    "                bitmap[point_a[0]][point_a[1]] = 1\n",
    "            if check_bitmap:\n",
    "                if bitmap[point_a[0]][point_a[1]]:\n",
    "                    return True\n",
    "        if point_a == point_b:\n",
    "            break\n",
    "        min_dis = np.inf\n",
    "        arg_min = None\n",
    "        for tx, ty in zip(xs, ys):\n",
    "            x, y = point_a[0] + tx, point_a[1] + ty\n",
    "            dis = np.sqrt((x - point_b[0]) ** 2 + (y - point_b[1]) ** 2)\n",
    "            if dis < min_dis:\n",
    "                min_dis = dis\n",
    "                arg_min = (x, y)\n",
    "        point_a = arg_min\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_unit_vector(point_a, point_b):\n",
    "    der_x = point_b[0] - point_a[0]\n",
    "    der_y = point_b[1] - point_a[1]\n",
    "    scale = 1 / math.sqrt(der_x ** 2 + der_y ** 2)\n",
    "    der_x *= scale\n",
    "    der_y *= scale\n",
    "    return (der_x, der_y)\n",
    "\n",
    "\n",
    "idx_in_batch_2_ans_points = {}\n",
    "idx_in_batch_2_ans_point_scores = {}\n",
    "\n",
    "\n",
    "def run_process_todo(queue, queue_res, speed=None, eval_time=None):\n",
    "    id = np.random.randint(5)\n",
    "    print('in run_process_todo', get_time(), id)\n",
    "\n",
    "\n",
    "def run_process(queue, queue_res, args):\n",
    "    id = np.random.randint(5)\n",
    "    utils_cython.args = args\n",
    "    objective = 'MR'\n",
    "    if 'MRminFDE' in args.other_params:\n",
    "        objective = 'MRminFDE'\n",
    "    opti_time = float(args.other_params.get('opti_time', 10000.0))\n",
    "\n",
    "    li = []\n",
    "    while True:\n",
    "        # print('a', round(time.time() - start_time, 2))\n",
    "        value = queue.get()\n",
    "        if value is None:\n",
    "            break\n",
    "        idx_in_batch, file_name, (goals_2D, scores), kwargs = value\n",
    "        scores = np.exp(scores)\n",
    "        if file_name == 'test_obs/data/33670.csv':\n",
    "            print('aaa', len(scores), np.sum(scores), scores, goals_2D)\n",
    "\n",
    "        if 'MRminFDE' in args.other_params:\n",
    "            assert 'cnt_sample' in args.other_params\n",
    "            MRratio = float(args.other_params['MRminFDE']) if args.other_params['MRminFDE'] is not True else 1.0\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        if 'cnt_sample' in args.other_params:\n",
    "            num_step = 1000\n",
    "            kwargs.update(dict(\n",
    "                num_step=num_step,\n",
    "                cnt_sample=args.other_params['cnt_sample'],\n",
    "                MRratio=MRratio,\n",
    "            ))\n",
    "            assert args.other_params['cnt_sample'] > 1\n",
    "\n",
    "        results = utils_cython.get_optimal_targets(goals_2D, scores, file_name, objective, opti_time, kwargs=kwargs)\n",
    "\n",
    "        li.append(round(time.time() - start_time, 2))\n",
    "\n",
    "        expectation, ans_points, pred_probs = results\n",
    "        queue_res.put((idx_in_batch, expectation, ans_points, pred_probs))\n",
    "    pass\n",
    "\n",
    "    print('out run_process', get_time(), id)\n",
    "\n",
    "\n",
    "def select_goals_by_optimization(batch_gt_points, mapping, close=False):\n",
    "    this = select_goals_by_optimization\n",
    "    if not hasattr(this, 'processes'):\n",
    "        # if end:\n",
    "        #     return\n",
    "        queue = multiprocessing.Queue(args.core_num)\n",
    "        queue_res = multiprocessing.Queue()\n",
    "        processes = [\n",
    "            Process(target=run_process, args=(queue, queue_res, args,))\n",
    "            for _ in range(args.core_num)]\n",
    "        for each in processes:\n",
    "            each.start()\n",
    "        this.processes = processes\n",
    "        this.queue = queue\n",
    "        this.queue_res = queue_res\n",
    "\n",
    "    queue = this.queue\n",
    "    queue_res = this.queue_res\n",
    "\n",
    "    if close:\n",
    "        for i in range(args.core_num):\n",
    "            queue.put(None)\n",
    "        for each in select_goals_by_optimization.processes:\n",
    "            each.join()\n",
    "        return\n",
    "\n",
    "    start_time = time.time()\n",
    "    batch_size, future_frame_num, _ = batch_gt_points.shape\n",
    "\n",
    "    batch_file_name = get_from_mapping(mapping, 'file_name')\n",
    "\n",
    "    assert args.core_num >= 2\n",
    "\n",
    "    run_times = 8\n",
    "    for _ in range(run_times):\n",
    "        for i in range(batch_size):\n",
    "            kwargs = {}\n",
    "            pass\n",
    "\n",
    "            queue.put((i, batch_file_name[i], mapping[i]['goals_2D_scores'], kwargs))\n",
    "\n",
    "    while not queue.empty():\n",
    "        pass\n",
    "\n",
    "    expectations = np.ones(batch_size) * 10000.0\n",
    "    batch_ans_points = np.zeros([batch_size, 6, 2])\n",
    "    batch_pred_probs = np.zeros([batch_size, 6])\n",
    "    for _ in range(run_times * batch_size):\n",
    "        i, expectation, ans_points, pred_probs = queue_res.get()\n",
    "        if expectation < expectations[i]:\n",
    "            expectations[i] = expectation\n",
    "            batch_ans_points[i] = ans_points\n",
    "            batch_pred_probs[i] = pred_probs\n",
    "\n",
    "    # print('here', round(time.time() - start_time, 2))\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        FDE = np.inf\n",
    "        if not args.do_test:\n",
    "            FDE = np.min(get_dis_point_2_points(batch_gt_points[i][-1], batch_ans_points[i]))\n",
    "        method2FDEs[0].append(FDE)\n",
    "\n",
    "        ans_points = batch_ans_points[i].copy()\n",
    "        if args.argoverse:\n",
    "            to_origin_coordinate(ans_points, i)\n",
    "\n",
    "    return batch_ans_points, batch_pred_probs\n",
    "\n",
    "\n",
    "def to_origin_coordinate(points, idx_in_batch, scale=None):\n",
    "    for point in points:\n",
    "        point[0], point[1] = rotate(point[0] - origin_point[idx_in_batch][0],\n",
    "                                    point[1] - origin_point[idx_in_batch][1], origin_angle[idx_in_batch])\n",
    "        if scale is not None:\n",
    "            point[0] *= scale\n",
    "            point[1] *= scale\n",
    "\n",
    "\n",
    "def to_relative_coordinate(points, x, y, angle):\n",
    "    for point in points:\n",
    "        point[0], point[1] = rotate(point[0] - x, point[1] - y, angle)\n",
    "\n",
    "\n",
    "def get_time():\n",
    "    return time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
    "\n",
    "\n",
    "time_begin = get_time()\n",
    "\n",
    "\n",
    "def assert_(satisfied, info=None):\n",
    "    if not satisfied:\n",
    "        if info is not None:\n",
    "            print(info)\n",
    "        print(sys._getframe().f_code.co_filename, sys._getframe().f_back.f_lineno)\n",
    "    assert satisfied\n",
    "\n",
    "\n",
    "def get_miss_rate(li_FDE, dis=2.0):\n",
    "    return np.sum(np.array(li_FDE) > dis) / len(li_FDE) if len(li_FDE) > 0 else None\n",
    "\n",
    "\n",
    "def ids_to_matrix(ids_list: List[List[int]], size, device):\n",
    "    tensor = torch.zeros([len(ids_list), size], device=device)\n",
    "    for idx, each_list in enumerate(ids_list):\n",
    "        if len(each_list) == 0:\n",
    "            continue\n",
    "        tensor[idx].scatter_(0, torch.tensor(each_list, device=device), 1.0)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def get_max_hidden(hidden_states: Tensor, pooling_mask: Tensor):\n",
    "    num_query = pooling_mask.shape[0]\n",
    "    num_key = pooling_mask.shape[1]\n",
    "    assert num_key == hidden_states.shape[0]\n",
    "    hidden_size = hidden_states.shape[1]\n",
    "    pooling_mask = (1.0 - pooling_mask) * -10000.0\n",
    "    hidden_states = hidden_states.unsqueeze(0).expand([num_query, num_key, hidden_size])\n",
    "    hidden_states = hidden_states + pooling_mask.unsqueeze(2)\n",
    "    return torch.max(hidden_states, dim=1)[0]\n",
    "\n",
    "\n",
    "return_values = None\n",
    "\n",
    "\n",
    "def model_return(*inputs):\n",
    "    if args.distributed_training:\n",
    "        global return_values\n",
    "        return_values = inputs[1:]\n",
    "        return inputs[0]\n",
    "    else:\n",
    "        return inputs\n",
    "\n",
    "\n",
    "def get_color_text(text, color='red'):\n",
    "    if color == 'red':\n",
    "        return \"\\033[31m\" + text + \"\\033[0m\"\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "\n",
    "other_errors_dict = defaultdict(list)\n",
    "\n",
    "\n",
    "def other_errors_put(error_type, error):\n",
    "    other_errors_dict[error_type].append(error)\n",
    "\n",
    "\n",
    "def other_errors_to_string():\n",
    "    res = {}\n",
    "    for each, value in other_errors_dict.items():\n",
    "        res[each] = np.mean(value)\n",
    "    return str(res)\n",
    "\n",
    "\n",
    "def get_points_remove_repeated(points, threshold=1.0):\n",
    "    grid = {}\n",
    "\n",
    "    def get_hash_point(point):\n",
    "        return round(point[0] / threshold), round(point[1] / threshold)\n",
    "\n",
    "    def get_de_hash_point(point):\n",
    "        return float(point[0] * threshold), float(point[1] * threshold)\n",
    "\n",
    "    for each in points:\n",
    "        grid[get_hash_point(each)] = True\n",
    "    return [get_de_hash_point(each) for each in list(grid.keys())]\n",
    "\n",
    "\n",
    "def get_dis_point_2_points(point, points):\n",
    "    assert points.ndim == 2\n",
    "    return np.sqrt(np.square(points[:, 0] - point[0]) + np.square(points[:, 1] - point[1]))\n",
    "\n",
    "\n",
    "def get_dis_point_2_polygons(point, polygons):\n",
    "    dis = np.zeros(len(polygons))\n",
    "    for i, each in enumerate(polygons):\n",
    "        dis[i] = np.min(np.sqrt(np.square(each[:, 0] - point[0]) + np.square(each[:, 1] - point[1])))\n",
    "    # dis = np.square(polygons[:, :, 0] - point[0]) + np.square(polygons[:, :, 1] - point[1])\n",
    "    # dis = np.min(dis, axis=-1)\n",
    "    # dis = np.sqrt(dis)\n",
    "    return dis\n",
    "\n",
    "\n",
    "_zip = zip\n",
    "\n",
    "\n",
    "def zip(*inputs):\n",
    "    for each in inputs:\n",
    "        assert len(each) == len(inputs[0])\n",
    "    return _zip(*inputs)\n",
    "\n",
    "\n",
    "def zip_enum(*inputs):\n",
    "    for each in inputs:\n",
    "        assert len(each) == len(inputs[0])\n",
    "    return zip(range(len(inputs[0])), *inputs)\n",
    "\n",
    "\n",
    "def point_in_points(point, points):\n",
    "    points = np.array(points)\n",
    "    if points.ndim != 2:\n",
    "        return False\n",
    "    dis = get_dis_point_2_points(point, points)\n",
    "    return np.min(dis) < 1.0 + eps\n",
    "\n",
    "\n",
    "def get_pseudo_label(predicts, labels, self_cost=None, kwargs={}):\n",
    "    if self_cost is None:\n",
    "        self_cost = np.zeros(len(predicts))\n",
    "    if isinstance(labels, list):\n",
    "        cost_list = []\n",
    "        pseudo_label_list = []\n",
    "        for each in labels:\n",
    "            pseudo_label, cost, _ = \\\n",
    "                utils_cython.get_pseudo_label(predicts.astype(np.float32), each.astype(np.float32), self_cost.astype(np.float32), kwargs)\n",
    "            pseudo_label_list.append(pseudo_label)\n",
    "            cost_list.append(cost)\n",
    "\n",
    "        argmin = np.argmin(np.array(cost_list))\n",
    "        return pseudo_label_list[argmin], cost_list[argmin], None\n",
    "    else:\n",
    "        return utils_cython.get_pseudo_label(predicts.astype(np.float32), labels.astype(np.float32), self_cost.astype(np.float32), kwargs)\n",
    "\n",
    "\n",
    "def get_file_name_int(file_name):\n",
    "    return int(os.path.split(file_name)[1][:-4])\n",
    "\n",
    "\n",
    "def assign(a, b, n=2):\n",
    "    if n == 2:\n",
    "        a[0], a[1] = b[0], b[1]\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "\n",
    "def my_print(*args):\n",
    "    print(*args)\n",
    "\n",
    "\n",
    "i_epoch = None\n",
    "\n",
    "\n",
    "def get_from_mapping(mapping: List[Dict], key=None):\n",
    "    if key is None:\n",
    "        line_context = inspect.getframeinfo(inspect.currentframe().f_back).code_context[0]\n",
    "        key = line_context.split('=')[0].strip()\n",
    "    return [each[key] for each in mapping]\n",
    "\n",
    "\n",
    "ap_list = None\n",
    "\n",
    "\n",
    "def metric_values_to_string(metric_values, metric_names, metric=None, index=None, append=False):\n",
    "    if metric_values == None:\n",
    "        print('metric_values is None')\n",
    "        return\n",
    "    lines = []\n",
    "    for i, m in enumerate(\n",
    "            ['min_ade', 'min_fde', 'miss_rate', 'overlap_rate', 'map']):\n",
    "        if metric is None or metric == m:\n",
    "            for j, n in enumerate(metric_names):\n",
    "                if index is None or index == j:\n",
    "                    if append and metric_values[i][j] > 0.0:\n",
    "                        ap_list.append(float(metric_values[i][j]))\n",
    "                    lines.append('{}/{}: {}'.format(m, n, metric_values[i][j]))\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "\n",
    "def pool_forward(rank, queue, result_queue, run):\n",
    "    while True:\n",
    "        file = queue.get()\n",
    "        if file is None:\n",
    "            break\n",
    "        result = run(*file)\n",
    "        result_queue.put(result)\n",
    "\n",
    "\n",
    "class Pool:\n",
    "    def __init__(self, core_num, files, run):\n",
    "        self.core_num = core_num\n",
    "        self.queue = multiprocessing.Queue(core_num)\n",
    "        self.result_queue = multiprocessing.Queue(core_num)\n",
    "        self.processes = [multiprocessing.Process(target=pool_forward, args=(rank, self.queue, self.result_queue, run,)) for rank in\n",
    "                          range(self.core_num)]\n",
    "        self.files = files\n",
    "        for each in self.processes:\n",
    "            each.start()\n",
    "        for file in files:\n",
    "            assert file is not None\n",
    "            self.queue.put(file)\n",
    "\n",
    "    def join(self):\n",
    "        results = []\n",
    "        for i in range(len(self.files)):\n",
    "            results.append(self.result_queue.get())\n",
    "\n",
    "        while not self.queue.empty():\n",
    "            pass\n",
    "\n",
    "        for i in range(self.core_num):\n",
    "            self.queue.put(None)\n",
    "\n",
    "        for each in self.processes:\n",
    "            each.join()\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "motion_metrics = None\n",
    "metric_names = None\n",
    "\n",
    "trajectory_type_2_motion_metrics = {}\n",
    "\n",
    "\n",
    "def get_trajectory_upsample(inputs: np.ndarray, future_frame_num, future_test_frame_num):\n",
    "    stride = future_frame_num // future_test_frame_num\n",
    "    shape_prefix = list(inputs.shape[:-2])\n",
    "    assert len(shape_prefix) > 0\n",
    "    inputs = inputs.reshape(-1, future_test_frame_num, future_frame_num)\n",
    "    outputs = np.zeros(len(inputs), future_frame_num, 2)\n",
    "    outputs[:, stride - 1::stride, :] = inputs\n",
    "    outputs = outputs.reshape(*shape_prefix, future_frame_num, 2)\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def get_eval_identifier():\n",
    "    eval_identifier = args.model_recover_path.split('/')[-1]\n",
    "    for each in args.eval_params:\n",
    "        each = str(each)\n",
    "        if len(each) > 15 and '=' in each:\n",
    "            each = each.split('=')[0]\n",
    "        if len(each) > 15:\n",
    "            each = 'long'\n",
    "        eval_identifier += '.' + str(each)\n",
    "    eval_identifier = get_name(eval_identifier, append_time=True)\n",
    "    return eval_identifier\n",
    "\n",
    "\n",
    "def get_wait5_rank(rank):\n",
    "    rank = rank + 1\n",
    "    return rank // 2\n",
    "\n",
    "\n",
    "# def shape_equal(shape, shape_):\n",
    "#     if len(shape) != len(shape_):\n",
    "#         return False\n",
    "\n",
    "class Normalizer:\n",
    "    def __init__(self, x, y, yaw):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.yaw = yaw\n",
    "        self.origin = rotate(0.0 - x, 0.0 - y, yaw)\n",
    "\n",
    "    def __call__(self, points, reverse=False):\n",
    "        points = np.array(points)\n",
    "        if points.shape == (2,):\n",
    "            points.shape = (1, 2)\n",
    "        assert len(points.shape) <= 3\n",
    "        if len(points.shape) == 3:\n",
    "            for each in points:\n",
    "                each[:] = self.__call__(each, reverse)\n",
    "        else:\n",
    "            assert len(points.shape) == 2\n",
    "            for point in points:\n",
    "                if reverse:\n",
    "                    point[0], point[1] = rotate(point[0] - self.origin[0],\n",
    "                                                point[1] - self.origin[1], -self.yaw)\n",
    "                else:\n",
    "                    point[0], point[1] = rotate(point[0] - self.x,\n",
    "                                                point[1] - self.y, self.yaw)\n",
    "\n",
    "        return points\n",
    "\n",
    "\n",
    "def satisfy_one_of(conds, other_params):\n",
    "    for each in conds:\n",
    "        if each in other_params:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_static_var(obj, name, default=None, path=None):\n",
    "    if not hasattr(obj, name):\n",
    "        if default is not None:\n",
    "            value = default\n",
    "        elif path is not None:\n",
    "            value = structs.load(path)\n",
    "        else:\n",
    "            assert False\n",
    "        setattr(obj, name, value)\n",
    "    return getattr(obj, name)\n",
    "\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abadac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple, NamedTuple, Any\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "\n",
    "#from modeling.decoder import Decoder, DecoderResCat\n",
    "#from modeling.lib import MLP, GlobalGraph, LayerNorm, CrossAttention, GlobalGraphRes\n",
    "#import utils\n",
    "global other_params\n",
    "other_params = []\n",
    "other_params.append('goals_2D')\n",
    "other_params.append('stage_one_dynamic')\n",
    "\n",
    "class NewSubGraph(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, depth=None):\n",
    "        super(NewSubGraph, self).__init__()\n",
    "        if depth is None:\n",
    "            depth = 3 #args.sub_graph_depth\n",
    "        self.layers = nn.ModuleList([MLP(hidden_size, hidden_size // 2) for _ in range(depth)])\n",
    "\n",
    "        self.layer_0 = MLP(hidden_size)\n",
    "        self.layers = nn.ModuleList([GlobalGraph(hidden_size, num_attention_heads=2) for _ in range(depth)])\n",
    "        self.layers_2 = nn.ModuleList([LayerNorm(hidden_size) for _ in range(depth)])\n",
    "        self.layers_3 = nn.ModuleList([LayerNorm(hidden_size) for _ in range(depth)])\n",
    "        self.layers_4 = nn.ModuleList([GlobalGraph(hidden_size) for _ in range(depth)])\n",
    "        #if 'point_level-4-3' in args.other_params:\n",
    "        self.layer_0_again = MLP(hidden_size)\n",
    "\n",
    "    def forward(self, input_list: list):\n",
    "        batch_size = len(input_list)\n",
    "        device = input_list[0].device\n",
    "        hidden_states, lengths = merge_tensors(input_list, device)\n",
    "        hidden_size = hidden_states.shape[2]\n",
    "        max_vector_num = hidden_states.shape[1]\n",
    "\n",
    "        attention_mask = torch.zeros([batch_size, max_vector_num, max_vector_num], device=device)\n",
    "        hidden_states = self.layer_0(hidden_states)\n",
    "\n",
    "        #if 'point_level-4-3' in args.other_params:\n",
    "        hidden_states = self.layer_0_again(hidden_states)\n",
    "        for i in range(batch_size):\n",
    "            assert lengths[i] > 0\n",
    "            attention_mask[i, :lengths[i], :lengths[i]].fill_(1)\n",
    "\n",
    "        for layer_index, layer in enumerate(self.layers):\n",
    "            temp = hidden_states\n",
    "            # hidden_states = layer(hidden_states, attention_mask)\n",
    "            # hidden_states = self.layers_2[layer_index](hidden_states)\n",
    "            # hidden_states = F.relu(hidden_states) + temp\n",
    "            hidden_states = layer(hidden_states, attention_mask)\n",
    "            hidden_states = F.relu(hidden_states)\n",
    "            hidden_states = hidden_states + temp\n",
    "            hidden_states = self.layers_2[layer_index](hidden_states)\n",
    "\n",
    "        return torch.max(hidden_states, dim=1)[0], torch.cat(de_merge_tensors(hidden_states, lengths))\n",
    "\n",
    "\n",
    "class VectorNet(nn.Module):\n",
    "    r\"\"\"\n",
    "    VectorNet\n",
    "    It has two main components, sub graph and global graph.\n",
    "    Sub graph encodes a polyline as a single vector.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args_: None):\n",
    "        super(VectorNet, self).__init__()\n",
    "        #global args\n",
    "        #args = args_\n",
    "        hidden_size = 128\n",
    "\n",
    "        self.point_level_sub_graph = NewSubGraph(hidden_size)\n",
    "        self.point_level_cross_attention = CrossAttention(hidden_size)\n",
    "\n",
    "        self.global_graph = GlobalGraph(hidden_size)\n",
    "        #if 'enhance_global_graph' in args.other_params:\n",
    "        self.global_graph = GlobalGraphRes(hidden_size)\n",
    "        #if 'laneGCN' in args.other_params:\n",
    "        self.laneGCN_A2L = CrossAttention(hidden_size)\n",
    "        self.laneGCN_L2L = GlobalGraphRes(hidden_size)\n",
    "        self.laneGCN_L2A = CrossAttention(hidden_size)\n",
    "\n",
    "        self.decoder = Decoder(None, self)\n",
    "\n",
    "        #if 'complete_traj' in args.other_params:\n",
    "        self.decoder.complete_traj_cross_attention = CrossAttention(hidden_size)\n",
    "        self.decoder.complete_traj_decoder = DecoderResCat(hidden_size, hidden_size * 3, out_features=self.decoder.future_frame_num * 2)\n",
    "\n",
    "    def forward_encode_sub_graph(self, mapping: List[Dict], matrix: List[np.ndarray], polyline_spans: List[List[slice]],\n",
    "                                 device, batch_size) -> Tuple[List[Tensor], List[Tensor]]:\n",
    "        \"\"\"\n",
    "        :param matrix: each value in list is vectors of all element (shape [-1, 128])\n",
    "        :param polyline_spans: vectors of i_th element is matrix[polyline_spans[i]]\n",
    "        :return: hidden states of all elements and hidden states of lanes\n",
    "        \"\"\"\n",
    "        input_list_list = []\n",
    "        # TODO(cyrushx): This is not used? Is it because input_list_list includes map data as well?\n",
    "        # Yes, input_list_list includes map data, this will be used in the future release.\n",
    "        map_input_list_list = []\n",
    "        lane_states_batch = None\n",
    "        for i in range(batch_size):\n",
    "            input_list = []\n",
    "            map_input_list = []\n",
    "            map_start_polyline_idx = mapping[i]['map_start_polyline_idx']\n",
    "            for j, polyline_span in enumerate(polyline_spans[i]):\n",
    "                tensor = torch.tensor(matrix[i][polyline_span], device=device)\n",
    "                input_list.append(tensor)\n",
    "                if j >= map_start_polyline_idx:\n",
    "                    map_input_list.append(tensor)\n",
    "\n",
    "            input_list_list.append(input_list)\n",
    "            map_input_list_list.append(map_input_list)\n",
    "\n",
    "        if True:\n",
    "            element_states_batch = []\n",
    "            for i in range(batch_size):\n",
    "                a, b = self.point_level_sub_graph(input_list_list[i])\n",
    "                element_states_batch.append(a)\n",
    "\n",
    "        #if 'stage_one' in args.other_params:\n",
    "        lane_states_batch = []\n",
    "        for i in range(batch_size):\n",
    "            a, b = self.point_level_sub_graph(map_input_list_list[i])\n",
    "            lane_states_batch.append(a)\n",
    "\n",
    "        #if 'laneGCN' in args.other_params:\n",
    "        inputs_before_laneGCN, inputs_lengths_before_laneGCN = merge_tensors(element_states_batch, device=device)\n",
    "        for i in range(batch_size):\n",
    "            map_start_polyline_idx = mapping[i]['map_start_polyline_idx']\n",
    "            agents = element_states_batch[i][:map_start_polyline_idx]\n",
    "            lanes = element_states_batch[i][map_start_polyline_idx:]\n",
    "            #if 'laneGCN-4' in args.other_params:\n",
    "            lanes = lanes + self.laneGCN_A2L(lanes.unsqueeze(0), torch.cat([lanes, agents[0:1]]).unsqueeze(0)).squeeze(0)\n",
    "            #else:\n",
    "            #    lanes = lanes + self.laneGCN_A2L(lanes.unsqueeze(0), agents.unsqueeze(0)).squeeze(0)\n",
    "            #    lanes = lanes + self.laneGCN_L2L(lanes.unsqueeze(0)).squeeze(0)\n",
    "            #    agents = agents + self.laneGCN_L2A(agents.unsqueeze(0), lanes.unsqueeze(0)).squeeze(0)\n",
    "            element_states_batch[i] = torch.cat([agents, lanes])\n",
    "\n",
    "        return element_states_batch, lane_states_batch\n",
    "\n",
    "    # @profile\n",
    "    def forward(self, mapping: List[Dict], device):\n",
    "        import time\n",
    "        global starttime\n",
    "        starttime = time.time()\n",
    "\n",
    "        matrix = get_from_mapping(mapping, 'matrix')\n",
    "        # TODO(cyrushx): Can you explain the structure of polyline spans?\n",
    "        # vectors of i_th element is matrix[polyline_spans[i]]\n",
    "        polyline_spans = get_from_mapping(mapping, 'polyline_spans')\n",
    "\n",
    "        batch_size = len(matrix)\n",
    "        # for i in range(batch_size):\n",
    "        # polyline_spans[i] = [slice(polyline_span[0], polyline_span[1]) for polyline_span in polyline_spans[i]]\n",
    "\n",
    "        if True:#args.argoverse:\n",
    "            batch_init(mapping)\n",
    "\n",
    "        element_states_batch, lane_states_batch = self.forward_encode_sub_graph(mapping, matrix, polyline_spans, device, batch_size)\n",
    "\n",
    "        inputs, inputs_lengths = merge_tensors(element_states_batch, device=device)\n",
    "        max_poly_num = max(inputs_lengths)\n",
    "        attention_mask = torch.zeros([batch_size, max_poly_num, max_poly_num], device=device)\n",
    "        for i, length in enumerate(inputs_lengths):\n",
    "            attention_mask[i][:length][:length].fill_(1)\n",
    "\n",
    "        hidden_states = self.global_graph(inputs, attention_mask, mapping)\n",
    "\n",
    "        #utils.logging('time3', round(time.time() - starttime, 2), 'secs')\n",
    "\n",
    "        return self.decoder(mapping, batch_size, lane_states_batch, inputs, inputs_lengths, hidden_states, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c69e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "\n",
    "#import structs\n",
    "#import utils_cython\n",
    "#from modeling.lib import PointSubGraph, GlobalGraphRes, CrossAttention, GlobalGraph, MLP\n",
    "#import utils\n",
    "\n",
    "\n",
    "class DecoderRes(nn.Module):\n",
    "    def __init__(self, hidden_size, out_features=60):\n",
    "        super(DecoderRes, self).__init__()\n",
    "        self.mlp = MLP(hidden_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, out_features)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = hidden_states + self.mlp(hidden_states)\n",
    "        hidden_states = self.fc(hidden_states)\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "class DecoderResCat(nn.Module):\n",
    "    def __init__(self, hidden_size, in_features, out_features=60):\n",
    "        super(DecoderResCat, self).__init__()\n",
    "        self.mlp = MLP(in_features, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size + in_features, out_features)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = torch.cat([hidden_states, self.mlp(hidden_states)], dim=-1)\n",
    "        hidden_states = self.fc(hidden_states)\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, _args:None, vectornet):\n",
    "        super(Decoder, self).__init__()\n",
    "        #global args\n",
    "        #args = args_\n",
    "        hidden_size = 128 \n",
    "        self.future_frame_num = 30 \n",
    "        self.mode_num = 6 \n",
    "\n",
    "        self.decoder = DecoderRes(hidden_size, out_features=2)\n",
    "\n",
    "        if 'variety_loss' in other_params:\n",
    "            self.variety_loss_decoder = DecoderResCat(hidden_size, hidden_size, out_features=6 * self.future_frame_num * 2)\n",
    "\n",
    "            if 'variety_loss-prob' in other_params:\n",
    "                self.variety_loss_decoder = DecoderResCat(hidden_size, hidden_size, out_features=6 * self.future_frame_num * 2 + 6)\n",
    "        elif 'goals_2D' in other_params:\n",
    "            #self.decoder = DecoderResCat(hidden_size, hidden_size, out_features=self.future_frame_num * 2)\n",
    "            self.goals_2D_mlps = nn.Sequential(\n",
    "                MLP(2, hidden_size),\n",
    "                MLP(hidden_size),\n",
    "                MLP(hidden_size)\n",
    "            )\n",
    "            #self.goals_2D_decoder = DecoderRes(hidden_size * 3, out_features=1)\n",
    "            self.goals_2D_decoder = DecoderResCat(hidden_size, hidden_size * 3, out_features=1)\n",
    "            self.goals_2D_cross_attention = CrossAttention(hidden_size)\n",
    "            #if 'point_sub_graph' in other_params:\n",
    "            self.goals_2D_point_sub_graph = PointSubGraph(hidden_size)\n",
    "        \n",
    "        #if 'stage_one' in other_params:\n",
    "        self.stage_one_cross_attention = CrossAttention(hidden_size)\n",
    "        self.stage_one_decoder = DecoderResCat(hidden_size, hidden_size * 3, out_features=1)\n",
    "        self.stage_one_goals_2D_decoder = DecoderResCat(hidden_size, hidden_size * 4, out_features=1)\n",
    "\n",
    "        if 'set_predict' in other_params:\n",
    "            if True:\n",
    "                if 'set_predict-train_recover' in other_params:\n",
    "                    model_recover = torch.load(other_params['set_predict-train_recover'])\n",
    "                else:\n",
    "                    model_recover = torch.load(model_recover_path)\n",
    "                vectornet.decoder = self\n",
    "                utils.load_model(vectornet, model_recover)\n",
    "                # self must be vectornet\n",
    "                for p in vectornet.parameters():\n",
    "                    p.requires_grad = False\n",
    "\n",
    "            self.set_predict_point_feature = nn.Sequential(MLP(3, hidden_size), MLP(hidden_size, hidden_size))\n",
    "\n",
    "            self.set_predict_encoders = nn.ModuleList(\n",
    "                [GlobalGraphRes(hidden_size) for _ in range(other_params['set_predict'])])\n",
    "\n",
    "            self.set_predict_decoders = nn.ModuleList(\n",
    "                [DecoderResCat(hidden_size, hidden_size * 2, out_features=13) for _ in range(other_params['set_predict'])])\n",
    "\n",
    "    def goals_2D_per_example_stage_one(self, i, mapping, lane_states_batch, inputs, inputs_lengths,\n",
    "                                       hidden_states, device, loss):\n",
    "        def get_stage_one_scores():\n",
    "            stage_one_hidden = lane_states_batch[i]\n",
    "            stage_one_hidden_attention = self.stage_one_cross_attention(\n",
    "                stage_one_hidden.unsqueeze(0), inputs[i][:inputs_lengths[i]].unsqueeze(0)).squeeze(0)\n",
    "            stage_one_scores = self.stage_one_decoder(torch.cat([hidden_states[i, 0, :].unsqueeze(0).expand(\n",
    "                stage_one_hidden.shape), stage_one_hidden, stage_one_hidden_attention], dim=-1))\n",
    "            stage_one_scores = stage_one_scores.squeeze(-1)\n",
    "            stage_one_scores = F.log_softmax(stage_one_scores, dim=-1)\n",
    "            return stage_one_scores\n",
    "\n",
    "        stage_one_scores = get_stage_one_scores()\n",
    "        assert len(stage_one_scores) == len(mapping[i]['polygons'])\n",
    "        mapping[i]['stage_one_scores'] = stage_one_scores\n",
    "        # print('stage_one_scores', stage_one_scores.requires_grad)\n",
    "        loss[i] += F.nll_loss(stage_one_scores.unsqueeze(0),\n",
    "                              torch.tensor([mapping[i]['stage_one_label']], device=device))\n",
    "        # print('stage_one_scores-2', loss[i].requires_grad)\n",
    "        if 'stage_one_dynamic' in other_params:\n",
    "            _, stage_one_topk_ids = torch.topk(stage_one_scores, k=len(stage_one_scores))\n",
    "            threshold = float(other_params['stage_one_dynamic'])\n",
    "            sum = 0.0\n",
    "            for idx, each in enumerate(torch.exp(stage_one_scores[stage_one_topk_ids])):\n",
    "                sum += each\n",
    "                if sum > threshold:\n",
    "                    stage_one_topk_ids = stage_one_topk_ids[:idx + 1]\n",
    "                    break\n",
    "            utils.other_errors_put('stage_one_k', len(stage_one_topk_ids))\n",
    "        else:\n",
    "            _, stage_one_topk_ids = torch.topk(stage_one_scores, k=min(stage_one_K, len(stage_one_scores)))\n",
    "\n",
    "        if mapping[i]['stage_one_label'] in stage_one_topk_ids.tolist():\n",
    "            utils.other_errors_put('stage_one_recall', 1.0)\n",
    "        else:\n",
    "            utils.other_errors_put('stage_one_recall', 0.0)\n",
    "\n",
    "        stage_one_topk = lane_states_batch[i][stage_one_topk_ids]\n",
    "        mapping[i]['stage_one_topk'] = stage_one_topk\n",
    "\n",
    "        return stage_one_topk_ids\n",
    "\n",
    "    def goals_2D_per_example_lazy_points(self, i, goals_2D, mapping, labels, device, scores,\n",
    "                                         get_scores_inputs, stage_one_topk_ids=None, gt_points=None):\n",
    "        #if args.argoverse:\n",
    "        k = 150\n",
    "        #else:\n",
    "        #    k = 40\n",
    "        _, topk_ids = torch.topk(scores, k=min(k, len(scores)))\n",
    "        topk_ids = topk_ids.tolist()\n",
    "\n",
    "        goals_2D_new = utils.get_neighbour_points(goals_2D[topk_ids], topk_ids=topk_ids, mapping=mapping[i])\n",
    "\n",
    "        goals_2D_new = torch.cat([torch.tensor(goals_2D_new, device=device, dtype=torch.float),\n",
    "                                  torch.tensor(goals_2D, device=device, dtype=torch.float)], dim=0)\n",
    "\n",
    "        old_vector_num = len(goals_2D)\n",
    "\n",
    "        goals_2D = np.array(goals_2D_new.tolist())\n",
    "        # print('len', len(goals_2D))\n",
    "\n",
    "        scores = self.get_scores(goals_2D_new, *get_scores_inputs)\n",
    "\n",
    "        index = torch.argmax(scores).item()\n",
    "        point = np.array(goals_2D_new[index].tolist())\n",
    "\n",
    "        if not args.do_test:\n",
    "            label = np.array(labels[i]).reshape([self.future_frame_num, 2])\n",
    "            final_idx = mapping[i].get('final_idx', -1)\n",
    "            mapping[i]['goals_2D_labels'] = np.argmin(utils.get_dis(goals_2D, label[final_idx]))\n",
    "\n",
    "        return scores, point, goals_2D\n",
    "\n",
    "    def goals_2D_per_example_calc_loss(self, i: int, goals_2D: np.ndarray, mapping: List[Dict], inputs: Tensor,\n",
    "                                       inputs_lengths: List[int], hidden_states: Tensor, device, loss: Tensor,\n",
    "                                       DE: np.ndarray, gt_points: np.ndarray, scores: Tensor, highest_goal: np.ndarray,\n",
    "                                       labels_is_valid: List[np.ndarray]):\n",
    "        \"\"\"\n",
    "        Calculate loss for a training example\n",
    "        \"\"\"\n",
    "        final_idx = mapping[i].get('final_idx', -1)\n",
    "        gt_goal = gt_points[final_idx]\n",
    "        DE[i][final_idx] = np.sqrt((highest_goal[0] - gt_points[final_idx][0]) ** 2 + (highest_goal[1] - gt_points[final_idx][1]) ** 2)\n",
    "        #if 'complete_traj' in args.other_params:\n",
    "        target_feature = self.goals_2D_mlps(torch.tensor(gt_points[final_idx], dtype=torch.float, device=device))\n",
    "        pass\n",
    "        if True:\n",
    "            target_feature.detach_()\n",
    "            hidden_attention = self.complete_traj_cross_attention(\n",
    "                target_feature.unsqueeze(0).unsqueeze(0), inputs[i][:inputs_lengths[i]].detach().unsqueeze(0)).squeeze(\n",
    "                0).squeeze(0)\n",
    "            predict_traj = self.complete_traj_decoder(\n",
    "                torch.cat([hidden_states[i, 0, :].detach(), target_feature, hidden_attention], dim=-1)).view(\n",
    "                [self.future_frame_num, 2])\n",
    "        loss[i] += (F.smooth_l1_loss(predict_traj, torch.tensor(gt_points, dtype=torch.float, device=device), reduction='none') * \\\n",
    "                    torch.tensor(labels_is_valid[i], dtype=torch.float, device=device).view(self.future_frame_num, 1)).mean()\n",
    "\n",
    "        loss[i] += F.nll_loss(scores.unsqueeze(0),\n",
    "                              torch.tensor([mapping[i]['goals_2D_labels']], device=device))\n",
    "\n",
    "    def goals_2D_per_example(self, i: int, goals_2D: np.ndarray, mapping: List[Dict], lane_states_batch: List[Tensor],\n",
    "                             inputs: Tensor, inputs_lengths: List[int], hidden_states: Tensor, labels: List[np.ndarray],\n",
    "                             labels_is_valid: List[np.ndarray], device, loss: Tensor, DE: np.ndarray):\n",
    "        \"\"\"\n",
    "        :param i: example index in batch\n",
    "        :param goals_2D: candidate goals sampled from map (shape ['goal num', 2])\n",
    "        :param lane_states_batch: each value in list is hidden states of lanes (value shape ['lane num', hidden_size])\n",
    "        :param inputs: hidden states of all elements before encoding by global graph (shape [batch_size, 'element num', hidden_size])\n",
    "        :param inputs_lengths: valid element number of each example\n",
    "        :param hidden_states: hidden states of all elements after encoding by global graph (shape [batch_size, -1, hidden_size])\n",
    "        :param loss: (shape [batch_size])\n",
    "        :param DE: displacement error (shape [batch_size, self.future_frame_num])\n",
    "        \"\"\"\n",
    "        if args.do_train:\n",
    "            final_idx = mapping[i].get('final_idx', -1)\n",
    "            assert labels_is_valid[i][final_idx]\n",
    "\n",
    "        gt_points = labels[i].reshape([self.future_frame_num, 2])\n",
    "\n",
    "        stage_one_topk_ids = None\n",
    "        if 'stage_one' in args.other_params:\n",
    "            stage_one_topk_ids = self.goals_2D_per_example_stage_one(i, mapping, lane_states_batch, inputs, inputs_lengths,\n",
    "                                                                     hidden_states, device, loss)\n",
    "\n",
    "        goals_2D_tensor = torch.tensor(goals_2D, device=device, dtype=torch.float)\n",
    "        get_scores_inputs = (inputs, hidden_states, inputs_lengths, i, mapping, device)\n",
    "\n",
    "        scores = self.get_scores(goals_2D_tensor, *get_scores_inputs)\n",
    "        index = torch.argmax(scores).item()\n",
    "        highest_goal = goals_2D[index]\n",
    "\n",
    "        #if 'lazy_points' in args.other_params:\n",
    "        scores, highest_goal, goals_2D = \\\n",
    "            self.goals_2D_per_example_lazy_points(i, goals_2D, mapping, labels, device, scores,\n",
    "                                                  get_scores_inputs, stage_one_topk_ids, gt_points)\n",
    "        index = None\n",
    "\n",
    "        if args.do_train:\n",
    "            self.goals_2D_per_example_calc_loss(i, goals_2D, mapping, inputs, inputs_lengths,\n",
    "                                                hidden_states, device, loss, DE, gt_points, scores, highest_goal, labels_is_valid)\n",
    "\n",
    "        if args.visualize:\n",
    "            mapping[i]['vis.goals_2D'] = goals_2D\n",
    "            mapping[i]['vis.scores'] = np.array(scores.tolist())\n",
    "            mapping[i]['vis.labels'] = gt_points\n",
    "            mapping[i]['vis.labels_is_valid'] = labels_is_valid[i]\n",
    "\n",
    "        if 'set_predict' in args.other_params:\n",
    "            self.run_set_predict(goals_2D, scores, mapping, device, loss, i)\n",
    "            if args.visualize:\n",
    "                set_predict_ans_points = mapping[i]['set_predict_ans_points']\n",
    "                predict_trajs = np.zeros((6, self.future_frame_num, 2))\n",
    "                predict_trajs[:, -1, :] = set_predict_ans_points\n",
    "\n",
    "        else:\n",
    "            if args.do_eval:\n",
    "                if args.nms_threshold is not None:\n",
    "                    utils.select_goals_by_NMS(mapping[i], goals_2D, np.array(scores.tolist()), args.nms_threshold, mapping[i]['speed'])\n",
    "                elif 'optimization' in args.other_params:\n",
    "                    mapping[i]['goals_2D_scores'] = goals_2D.astype(np.float32), np.array(scores.tolist(), dtype=np.float32)\n",
    "                else:\n",
    "                    assert False\n",
    "\n",
    "    def goals_2D_eval(self, batch_size, mapping, labels, hidden_states, inputs, inputs_lengths, device):\n",
    "        if 'set_predict' in args.other_params:\n",
    "            pred_goals_batch = [mapping[i]['set_predict_ans_points'] for i in range(batch_size)]\n",
    "            pred_probs_batch = np.zeros((batch_size, 6))\n",
    "        elif 'optimization' in args.other_params:\n",
    "            pred_goals_batch, pred_probs_batch = utils.select_goals_by_optimization(\n",
    "                np.array(labels).reshape([batch_size, self.future_frame_num, 2]), mapping)\n",
    "        elif args.nms_threshold is not None:\n",
    "            pred_goals_batch = [mapping[i]['pred_goals'] for i in range(batch_size)]\n",
    "            pred_probs_batch = [mapping[i]['pred_probs'] for i in range(batch_size)]\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "        pred_goals_batch = np.array(pred_goals_batch)\n",
    "        pred_probs_batch = np.array(pred_probs_batch)\n",
    "        assert pred_goals_batch.shape == (batch_size, self.mode_num, 2)\n",
    "        assert pred_probs_batch.shape == (batch_size, self.mode_num)\n",
    "\n",
    "        if 'complete_traj' in args.other_params:\n",
    "            pred_trajs_batch = []\n",
    "            for i in range(batch_size):\n",
    "                targets_feature = self.goals_2D_mlps(torch.tensor(pred_goals_batch[i], dtype=torch.float, device=device))\n",
    "                hidden_attention = self.complete_traj_cross_attention(\n",
    "                    targets_feature.unsqueeze(0), inputs[i][:inputs_lengths[i]].unsqueeze(0)).squeeze(0)\n",
    "                predict_trajs = self.complete_traj_decoder(\n",
    "                    torch.cat([hidden_states[i, 0, :].unsqueeze(0).expand(len(targets_feature), -1), targets_feature,\n",
    "                               hidden_attention], dim=-1)).view([self.mode_num, self.future_frame_num, 2])\n",
    "                predict_trajs = np.array(predict_trajs.tolist())\n",
    "                final_idx = mapping[i].get('final_idx', -1)\n",
    "                predict_trajs[:, final_idx, :] = pred_goals_batch[i]\n",
    "                mapping[i]['vis.predict_trajs'] = predict_trajs.copy()\n",
    "\n",
    "                if args.argoverse:\n",
    "                    for each in predict_trajs:\n",
    "                        utils.to_origin_coordinate(each, i)\n",
    "                pred_trajs_batch.append(predict_trajs)\n",
    "            pred_trajs_batch = np.array(pred_trajs_batch)\n",
    "        else:\n",
    "            pass\n",
    "        if args.visualize:\n",
    "            for i in range(batch_size):\n",
    "                utils.visualize_goals_2D(mapping[i], mapping[i]['vis.goals_2D'], mapping[i]['vis.scores'], self.future_frame_num,\n",
    "                                         labels=mapping[i]['vis.labels'],\n",
    "                                         labels_is_valid=mapping[i]['vis.labels_is_valid'],\n",
    "                                         predict=mapping[i]['vis.predict_trajs'])\n",
    "\n",
    "        return pred_trajs_batch, pred_probs_batch, None\n",
    "\n",
    "    def variety_loss(self, mapping: List[Dict], hidden_states: Tensor, batch_size, inputs: Tensor,\n",
    "                     inputs_lengths: List[int], labels_is_valid: List[np.ndarray], loss: Tensor,\n",
    "                     DE: np.ndarray, device, labels: List[np.ndarray]):\n",
    "        \"\"\"\n",
    "        :param hidden_states: hidden states of all elements after encoding by global graph (shape [batch_size, -1, hidden_size])\n",
    "        :param inputs: hidden states of all elements before encoding by global graph (shape [batch_size, 'element num', hidden_size])\n",
    "        :param inputs_lengths: valid element number of each example\n",
    "        :param DE: displacement error (shape [batch_size, self.future_frame_num])\n",
    "        \"\"\"\n",
    "        outputs = self.variety_loss_decoder(hidden_states[:, 0, :])\n",
    "        pred_probs = None\n",
    "        if 'variety_loss-prob' in args.other_params:\n",
    "            pred_probs = F.log_softmax(outputs[:, -6:], dim=-1)\n",
    "            outputs = outputs[:, :-6].view([batch_size, 6, self.future_frame_num, 2])\n",
    "        else:\n",
    "            outputs = outputs.view([batch_size, 6, self.future_frame_num, 2])\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            if args.do_train:\n",
    "                assert labels_is_valid[i][-1]\n",
    "            gt_points = np.array(labels[i]).reshape([self.future_frame_num, 2])\n",
    "            argmin = np.argmin(utils.get_dis_point_2_points(gt_points[-1], np.array(outputs[i, :, -1, :].tolist())))\n",
    "\n",
    "            loss_ = F.smooth_l1_loss(outputs[i, argmin],\n",
    "                                     torch.tensor(gt_points, device=device, dtype=torch.float), reduction='none')\n",
    "            loss_ = loss_ * torch.tensor(labels_is_valid[i], device=device, dtype=torch.float).view(self.future_frame_num, 1)\n",
    "            if labels_is_valid[i].sum() > utils.eps:\n",
    "                loss[i] += loss_.sum() / labels_is_valid[i].sum()\n",
    "\n",
    "            if 'variety_loss-prob' in args.other_params:\n",
    "                loss[i] += F.nll_loss(pred_probs[i].unsqueeze(0), torch.tensor([argmin], device=device))\n",
    "        if args.do_eval:\n",
    "            outputs = np.array(outputs.tolist())\n",
    "            pred_probs = np.array(pred_probs.tolist(), dtype=np.float32) if pred_probs is not None else pred_probs\n",
    "            for i in range(batch_size):\n",
    "                for each in outputs[i]:\n",
    "                    utils.to_origin_coordinate(each, i)\n",
    "\n",
    "            return outputs, pred_probs, None\n",
    "        return loss.mean(), DE, None\n",
    "\n",
    "    def forward(self, mapping: List[Dict], batch_size, lane_states_batch: List[Tensor], inputs: Tensor,\n",
    "                inputs_lengths: List[int], hidden_states: Tensor, device):\n",
    "        \"\"\"\n",
    "        :param lane_states_batch: each value in list is hidden states of lanes (value shape ['lane num', hidden_size])\n",
    "        :param inputs: hidden states of all elements before encoding by global graph (shape [batch_size, 'element num', hidden_size])\n",
    "        :param inputs_lengths: valid element number of each example\n",
    "        :param hidden_states: hidden states of all elements after encoding by global graph (shape [batch_size, 'element num', hidden_size])\n",
    "        \"\"\"\n",
    "        labels = utils.get_from_mapping(mapping, 'labels')\n",
    "        labels_is_valid = utils.get_from_mapping(mapping, 'labels_is_valid')\n",
    "        loss = torch.zeros(batch_size, device=device)\n",
    "        DE = np.zeros([batch_size, self.future_frame_num])\n",
    "\n",
    "        if 'variety_loss' in args.other_params:\n",
    "            return self.variety_loss(mapping, hidden_states, batch_size, inputs, inputs_lengths, labels_is_valid, loss, DE, device, labels)\n",
    "        elif 'goals_2D' in args.other_params:\n",
    "            for i in range(batch_size):\n",
    "                goals_2D = mapping[i]['goals_2D']\n",
    "\n",
    "                self.goals_2D_per_example(i, goals_2D, mapping, lane_states_batch, inputs, inputs_lengths,\n",
    "                                          hidden_states, labels, labels_is_valid, device, loss, DE)\n",
    "\n",
    "            if 'set_predict' in args.other_params:\n",
    "                pass\n",
    "                # if args.do_eval:\n",
    "                #     pred_trajs_batch = np.zeros([batch_size, 6, self.future_frame_num, 2])\n",
    "                #     for i in range(batch_size):\n",
    "                #         if 'set_predict_trajs' in mapping[i]:\n",
    "                #             pred_trajs_batch[i] = mapping[i]['set_predict_trajs']\n",
    "                #             for each in pred_trajs_batch[i]:\n",
    "                #                 utils.to_origin_coordinate(each, i)\n",
    "                #     return pred_trajs_batch\n",
    "\n",
    "            if args.do_eval:\n",
    "                return self.goals_2D_eval(batch_size, mapping, labels, hidden_states, inputs, inputs_lengths, device)\n",
    "            else:\n",
    "                if args.visualize:\n",
    "                    for i in range(batch_size):\n",
    "                        predict = np.zeros((self.mode_num, self.future_frame_num, 2))\n",
    "                        utils.visualize_goals_2D(mapping[i], mapping[i]['vis.goals_2D'], mapping[i]['vis.scores'],\n",
    "                                                 self.future_frame_num,\n",
    "                                                 labels=mapping[i]['vis.labels'],\n",
    "                                                 labels_is_valid=mapping[i]['vis.labels_is_valid'],\n",
    "                                                 predict=predict)\n",
    "                return loss.mean(), DE, None\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "    def get_scores(self, goals_2D_tensor: Tensor, inputs, hidden_states, inputs_lengths, i, mapping, device):\n",
    "        \"\"\"\n",
    "        :param goals_2D_tensor: candidate goals sampled from map (shape ['goal num', 2])\n",
    "        :return: log scores of goals (shape ['goal num'])\n",
    "        \"\"\"\n",
    "        if 'point_sub_graph' in args.other_params:\n",
    "            goals_2D_hidden = self.goals_2D_point_sub_graph(goals_2D_tensor.unsqueeze(0), hidden_states[i, 0:1, :]).squeeze(0)\n",
    "        else:\n",
    "            goals_2D_hidden = self.goals_2D_mlps(goals_2D_tensor)\n",
    "\n",
    "        goals_2D_hidden_attention = self.goals_2D_cross_attention(\n",
    "            goals_2D_hidden.unsqueeze(0), inputs[i][:inputs_lengths[i]].unsqueeze(0)).squeeze(0)\n",
    "\n",
    "        if 'stage_one' in args.other_params:\n",
    "            stage_one_topk = mapping[i]['stage_one_topk']\n",
    "            stage_one_scores = mapping[i]['stage_one_scores']\n",
    "            stage_one_topk_here = stage_one_topk\n",
    "            stage_one_goals_2D_hidden_attention = self.goals_2D_cross_attention(\n",
    "                goals_2D_hidden.unsqueeze(0), stage_one_topk_here.unsqueeze(0)).squeeze(0)\n",
    "            li = [hidden_states[i, 0, :].unsqueeze(0).expand(goals_2D_hidden.shape),\n",
    "                  goals_2D_hidden, goals_2D_hidden_attention, stage_one_goals_2D_hidden_attention]\n",
    "\n",
    "            scores = self.stage_one_goals_2D_decoder(torch.cat(li, dim=-1))\n",
    "        else:\n",
    "            scores = self.goals_2D_decoder(torch.cat([hidden_states[i, 0, :].unsqueeze(0).expand(\n",
    "                goals_2D_hidden.shape), goals_2D_hidden, goals_2D_hidden_attention], dim=-1))\n",
    "\n",
    "        scores = scores.squeeze(-1)\n",
    "        scores = F.log_softmax(scores, dim=-1)\n",
    "        return scores\n",
    "\n",
    "    def run_set_predict(self, goals_2D, scores, mapping, device, loss, i):\n",
    "        gt_points = mapping[i]['labels'].reshape((self.future_frame_num, 2))\n",
    "\n",
    "        if args.argoverse:\n",
    "            if 'set_predict-topk' in args.other_params:\n",
    "                topk_num = args.other_params['set_predict-topk']\n",
    "\n",
    "                if topk_num == 0:\n",
    "                    topk_num = torch.sum(scores > np.log(0.00001)).item()\n",
    "\n",
    "                _, topk_ids = torch.topk(scores, k=min(topk_num, len(scores)))\n",
    "                goals_2D = goals_2D[topk_ids.cpu().numpy()]\n",
    "                scores = scores[topk_ids]\n",
    "\n",
    "        scores_positive_np = np.exp(np.array(scores.tolist(), dtype=np.float32))\n",
    "        goals_2D = goals_2D.astype(np.float32)\n",
    "\n",
    "        max_point_idx = torch.argmax(scores)\n",
    "        vectors_3D = torch.cat([torch.tensor(goals_2D, device=device, dtype=torch.float), scores.unsqueeze(1)], dim=-1)\n",
    "        vectors_3D = torch.tensor(vectors_3D.tolist(), device=device, dtype=torch.float)\n",
    "\n",
    "        vectors_3D[:, 0] -= goals_2D[max_point_idx, 0]\n",
    "        vectors_3D[:, 1] -= goals_2D[max_point_idx, 1]\n",
    "\n",
    "        points_feature = self.set_predict_point_feature(vectors_3D)\n",
    "        costs = np.zeros(args.other_params['set_predict'])\n",
    "        pseudo_labels = []\n",
    "        predicts = []\n",
    "\n",
    "        set_predict_trajs_list = []\n",
    "        group_scores = torch.zeros([len(self.set_predict_encoders)], device=device)\n",
    "\n",
    "        start_time = utils.time.time()\n",
    "\n",
    "        if True:\n",
    "            for k, (encoder, decoder) in enumerate(zip(self.set_predict_encoders, self.set_predict_decoders)):\n",
    "                if 'set_predict-one_encoder' in args.other_params:\n",
    "                    encoder = self.set_predict_encoders[0]\n",
    "\n",
    "                if True:\n",
    "                    if 'set_predict-one_encoder' in args.other_params and k > 0:\n",
    "                        pass\n",
    "                    else:\n",
    "                        encoding = encoder(points_feature.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "                    decoding = decoder(torch.cat([torch.max(encoding, dim=0)[0], torch.mean(encoding, dim=0)], dim=-1)).view([13])\n",
    "                    group_scores[k] = decoding[0]\n",
    "                    predict = decoding[1:].view([6, 2])\n",
    "\n",
    "                    predict[:, 0] += goals_2D[max_point_idx, 0]\n",
    "                    predict[:, 1] += goals_2D[max_point_idx, 1]\n",
    "\n",
    "                predicts.append(predict)\n",
    "\n",
    "                if args.do_eval:\n",
    "                    pass\n",
    "                else:\n",
    "                    selected_points = np.array(predict.tolist(), dtype=np.float32)\n",
    "                    temp = None\n",
    "                    assert goals_2D.dtype == np.float32, goals_2D.dtype\n",
    "                    kwargs = None\n",
    "                    if 'set_predict-MRratio' in args.other_params:\n",
    "                        kwargs = {}\n",
    "                        kwargs['set_predict-MRratio'] = args.other_params['set_predict-MRratio']\n",
    "                    costs[k] = utils_cython.set_predict_get_value(goals_2D, scores_positive_np, selected_points, kwargs=kwargs)\n",
    "\n",
    "                    pseudo_labels.append(temp)\n",
    "\n",
    "        argmin = torch.argmax(group_scores).item()\n",
    "\n",
    "        if args.do_train:\n",
    "            utils.other_errors_put('set_hungary', np.min(costs))\n",
    "            group_scores = F.log_softmax(group_scores, dim=-1)\n",
    "            min_cost_idx = np.argmin(costs)\n",
    "            loss[i] = 0\n",
    "\n",
    "            if True:\n",
    "                selected_points = np.array(predicts[min_cost_idx].tolist(), dtype=np.float32)\n",
    "                kwargs = None\n",
    "                if 'set_predict-MRratio' in args.other_params:\n",
    "                    kwargs = {}\n",
    "                    kwargs['set_predict-MRratio'] = args.other_params['set_predict-MRratio']\n",
    "                _, dynamic_label = utils_cython.set_predict_next_step(goals_2D, scores_positive_np, selected_points,\n",
    "                                                                      lr=args.set_predict_lr, kwargs=kwargs)\n",
    "                # loss[i] += 2.0 / globals.set_predict_lr * \\\n",
    "                #            F.l1_loss(predicts[min_cost_idx], torch.tensor(dynamic_label, device=device, dtype=torch.float))\n",
    "                loss[i] += 2.0 * F.l1_loss(predicts[min_cost_idx], torch.tensor(dynamic_label, device=device, dtype=torch.float))\n",
    "\n",
    "            loss[i] += F.nll_loss(group_scores.unsqueeze(0), torch.tensor([min_cost_idx], device=device))\n",
    "\n",
    "            t = np.array(predicts[min_cost_idx].tolist())\n",
    "\n",
    "            utils.other_errors_put('set_MR_mincost', np.min(utils.get_dis_point_2_points(gt_points[-1], t)) > 2.0)\n",
    "            utils.other_errors_put('set_minFDE_mincost', np.min(utils.get_dis_point_2_points(gt_points[-1], t)))\n",
    "\n",
    "        predict = np.array(predicts[argmin].tolist())\n",
    "\n",
    "        set_predict_ans_points = predict.copy()\n",
    "        li = []\n",
    "        for point in set_predict_ans_points:\n",
    "            li.append((point, scores[np.argmin(utils.get_dis_point_2_points(point, goals_2D))]))\n",
    "        li = sorted(li, key=lambda x: -x[1])\n",
    "        set_predict_ans_points = np.array([each[0] for each in li])\n",
    "        mapping[i]['set_predict_ans_points'] = set_predict_ans_points\n",
    "\n",
    "        if args.argoverse:\n",
    "            utils.other_errors_put('set_MR_pred', np.min(utils.get_dis_point_2_points(gt_points[-1], predict)) > 2.0)\n",
    "            utils.other_errors_put('set_minFDE_pred', np.min(utils.get_dis_point_2_points(gt_points[-1], predict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4013632",
   "metadata": {},
   "outputs": [],
   "source": [
    " model_densetnt = VectorNet(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2e73a0",
   "metadata": {},
   "source": [
    "## LANE-GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fc9a910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fractions import gcd\n",
    "from numbers import Number\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "# Conv layer with norm (gn or bn) and relu. \n",
    "class Conv(nn.Module):\n",
    "    def __init__(self, n_in, n_out, kernel_size=3, stride=1, norm='GN', ng=32, act=True):\n",
    "        super(Conv, self).__init__()\n",
    "        assert(norm in ['GN', 'BN', 'SyncBN'])\n",
    "\n",
    "        self.conv = nn.Conv2d(n_in, n_out, kernel_size=kernel_size, padding=(int(kernel_size) - 1) // 2, stride=stride, bias=False)\n",
    "        \n",
    "        if norm == 'GN':\n",
    "            self.norm = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "        elif norm == 'BN':\n",
    "            self.norm = nn.BatchNorm2d(n_out)\n",
    "        else:\n",
    "            exit('SyncBN has not been added!')\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.act = act    \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.norm(out)\n",
    "        if self.act:\n",
    "            out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Conv1d(nn.Module):\n",
    "    def __init__(self, n_in, n_out, kernel_size=3, stride=1, norm='GN', ng=32, act=True):\n",
    "        super(Conv1d, self).__init__()\n",
    "        assert(norm in ['GN', 'BN', 'SyncBN'])\n",
    "\n",
    "        self.conv = nn.Conv1d(n_in, n_out, kernel_size=kernel_size, padding=(int(kernel_size) - 1) // 2, stride=stride, bias=False)\n",
    "\n",
    "        if norm == 'GN':\n",
    "            self.norm = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "        elif norm == 'BN':\n",
    "            self.norm = nn.BatchNorm1d(n_out)\n",
    "        else:\n",
    "            exit('SyncBN has not been added!')\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.norm(out)\n",
    "        if self.act:\n",
    "            out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, n_in, n_out, norm='GN', ng=32, act=True):\n",
    "        super(Linear, self).__init__()\n",
    "        assert(norm in ['GN', 'BN', 'SyncBN'])\n",
    "\n",
    "        self.linear = nn.Linear(n_in, n_out, bias=False)\n",
    "        \n",
    "        if norm == 'GN':\n",
    "            self.norm = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "        elif norm == 'BN':\n",
    "            self.norm = nn.BatchNorm1d(n_out)\n",
    "        else:\n",
    "            exit('SyncBN has not been added!')\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = self.norm(out)\n",
    "        if self.act:\n",
    "            out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Post residual layer\n",
    "class PostRes(nn.Module):\n",
    "    def __init__(self, n_in, n_out, stride=1, norm='GN', ng=32, act=True):\n",
    "        super(PostRes, self).__init__()\n",
    "        assert(norm in ['GN', 'BN', 'SyncBN'])\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(n_in, n_out, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(n_out, n_out, kernel_size=3, padding=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "        # All use name bn1 and bn2 to load imagenet pretrained weights\n",
    "        if norm == 'GN':\n",
    "            self.bn1 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "            self.bn2 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "        elif norm == 'BN':\n",
    "            self.bn1 = nn.BatchNorm2d(n_out)\n",
    "            self.bn2 = nn.BatchNorm2d(n_out)\n",
    "        else:\n",
    "            exit('SyncBN has not been added!')\n",
    "\n",
    "        if stride != 1 or n_out != n_in:\n",
    "            if norm == 'GN':\n",
    "                self.downsample = nn.Sequential(\n",
    "                        nn.Conv2d(n_in, n_out, kernel_size=1, stride=stride, bias=False),\n",
    "                        nn.GroupNorm(gcd(ng, n_out), n_out))\n",
    "            elif norm == 'BN':\n",
    "                self.downsample = nn.Sequential(\n",
    "                        nn.Conv2d(n_in, n_out, kernel_size=1, stride=stride, bias=False),\n",
    "                        nn.BatchNorm2d(n_out))\n",
    "            else:\n",
    "                exit('SyncBN has not been added!')    \n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "\n",
    "        out += x\n",
    "        if self.act:\n",
    "            out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Res1d(nn.Module):\n",
    "    def __init__(self, n_in, n_out, kernel_size=3, stride=1, norm='GN', ng=32, act=True):\n",
    "        super(Res1d, self).__init__()\n",
    "        assert(norm in ['GN', 'BN', 'SyncBN'])\n",
    "        padding = (int(kernel_size) - 1) // 2\n",
    "        self.conv1 = nn.Conv1d(n_in, n_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=False)\n",
    "        self.conv2 = nn.Conv1d(n_out, n_out, kernel_size=kernel_size, padding=padding, bias=False)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "\n",
    "        # All use name bn1 and bn2 to load imagenet pretrained weights\n",
    "        if norm == 'GN':\n",
    "            self.bn1 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "            self.bn2 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "        elif norm == 'BN':\n",
    "            self.bn1 = nn.BatchNorm1d(n_out)\n",
    "            self.bn2 = nn.BatchNorm1d(n_out)\n",
    "        else:\n",
    "            exit('SyncBN has not been added!')\n",
    "\n",
    "        if stride != 1 or n_out != n_in:\n",
    "            if norm == 'GN':\n",
    "                self.downsample = nn.Sequential(\n",
    "                        nn.Conv1d(n_in, n_out, kernel_size=1, stride=stride, bias=False),\n",
    "                        nn.GroupNorm(gcd(ng, n_out), n_out))\n",
    "            elif norm == 'BN':\n",
    "                self.downsample = nn.Sequential(\n",
    "                        nn.Conv1d(n_in, n_out, kernel_size=1, stride=stride, bias=False),\n",
    "                        nn.BatchNorm1d(n_out))\n",
    "            else:\n",
    "                exit('SyncBN has not been added!')\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "\n",
    "        out += x\n",
    "        if self.act:\n",
    "            out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class LinearRes(nn.Module):\n",
    "    def __init__(self, n_in, n_out, norm='GN', ng=32):\n",
    "        super(LinearRes, self).__init__()\n",
    "        assert(norm in ['GN', 'BN', 'SyncBN'])\n",
    "\n",
    "        self.linear1 = nn.Linear(n_in, n_out, bias=False)\n",
    "        self.linear2 = nn.Linear(n_out, n_out, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        if norm == 'GN':\n",
    "            self.norm1 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "            self.norm2 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
    "        elif norm == 'BN':\n",
    "            self.norm1 = nn.BatchNorm1d(n_out)\n",
    "            self.norm2 = nn.BatchNorm1d(n_out)\n",
    "        else:   \n",
    "            exit('SyncBN has not been added!')\n",
    "\n",
    "        if n_in != n_out:\n",
    "            if norm == 'GN':\n",
    "                self.transform = nn.Sequential(\n",
    "                    nn.Linear(n_in, n_out, bias=False),\n",
    "                    nn.GroupNorm(gcd(ng, n_out), n_out))\n",
    "            elif norm == 'BN':\n",
    "                self.transform = nn.Sequential(\n",
    "                    nn.Linear(n_in, n_out, bias=False),\n",
    "                    nn.BatchNorm1d(n_out))\n",
    "            else:\n",
    "                exit('SyncBN has not been added!')\n",
    "        else:\n",
    "            self.transform = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.norm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.norm2(out)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            out += self.transform(x)\n",
    "        else:\n",
    "            out += x\n",
    "\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Null(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Null, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "def linear_interp(x, n_max):\n",
    "    \"\"\"Given a Tensor of normed positions, returns linear interplotion weights and indices.\n",
    "    Example: For position 1.2, its neighboring pixels have indices 0 and 1, corresponding\n",
    "    to coordinates 0.5 and 1.5 (center of the pixel), and linear weights are 0.3 and 0.7.\n",
    "    Args:\n",
    "        x: Normalizzed positions, ranges from 0 to 1, float Tensor.\n",
    "        n_max: Size of the dimension (pixels), multiply x to get absolution positions.\n",
    "    Returns: Weights and indices of left side and right side.\n",
    "    \"\"\"\n",
    "    x = x * n_max - 0.5\n",
    "\n",
    "    mask = x < 0\n",
    "    x[mask] = 0\n",
    "    mask = x > n_max - 1\n",
    "    x[mask] = n_max - 1\n",
    "    n = torch.floor(x)\n",
    "\n",
    "    rw = x - n\n",
    "    lw = 1.0 - rw\n",
    "    li = n.long()\n",
    "    ri = li + 1\n",
    "    mask = ri > n_max - 1\n",
    "    ri[mask] = n_max - 1\n",
    "\n",
    "    return lw, li, rw, ri\n",
    "\n",
    "\n",
    "def get_pixel_feat(fm, bboxes, pts_range):\n",
    "    x, y = bboxes[:, 0], bboxes[:, 1]\n",
    "    x_min, x_max, y_min, y_max = pts_range[:4]\n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    y = (y_max - y) / (y_max - y_min)\n",
    "\n",
    "    _, fm_h, fm_w = fm.size()\n",
    "    xlw, xli, xhw, xhi = linear_interp(x, fm_w)\n",
    "    ylw, yli, yhw, yhi = linear_interp(y, fm_h)\n",
    "    feat = \\\n",
    "        (xlw * ylw).unsqueeze(1) * fm[:, yli, xli].transpose(0, 1) +\\\n",
    "        (xlw * yhw).unsqueeze(1) * fm[:, yhi, xli].transpose(0, 1) +\\\n",
    "        (xhw * ylw).unsqueeze(1) * fm[:, yli, xhi].transpose(0, 1) +\\\n",
    "        (xhw * yhw).unsqueeze(1) * fm[:, yhi, xhi].transpose(0, 1)\n",
    "    return feat\n",
    "\n",
    "\n",
    "def get_roi_feat(fm, bboxes, roi_size, pts_range):\n",
    "    \"\"\"Given a set of BEV bboxes get their BEV ROI features.\n",
    "    Args:\n",
    "        fm: Feature map, float tensor, chw\n",
    "        bboxes: BEV bboxes, n x 5 float tensor (cx, cy, wid, hgt, theta)\n",
    "        roi_size: ROI size (number of bins), [int] or int\n",
    "        pts_range: Range of points, tuple of ints, (x_min, x_max, y_min, y_max, z_min, z_max)\n",
    "    Returns: Extracted features of size (num_roi, c, roi_size, roi_size).\n",
    "    \"\"\"\n",
    "    if isinstance(roi_size, Number):\n",
    "        roi_size = [roi_size, roi_size]\n",
    "\n",
    "    cx, cy, wid, hgt, theta = bboxes[:, 0], bboxes[:, 1], bboxes[:, 2], bboxes[:, 3], bboxes[:, 4]\n",
    "    st = torch.sin(theta)\n",
    "    ct = torch.cos(theta)\n",
    "    num_bboxes = len(bboxes)\n",
    "\n",
    "    rot_mat = bboxes.new().resize_(num_bboxes, 2, 2)\n",
    "    rot_mat[:, 0, 0] = ct\n",
    "    rot_mat[:, 0, 1] = -st\n",
    "    rot_mat[:, 1, 0] = st\n",
    "    rot_mat[:, 1, 1] = ct\n",
    "\n",
    "    offset = bboxes.new().resize_(len(bboxes), roi_size[0], roi_size[1], 2)\n",
    "    x_bin = (torch.arange(roi_size[1]).float().to(bboxes.device) + 0.5) / roi_size[1] - 0.5\n",
    "    offset[:, :, :, 0] = x_bin.view(1, 1, -1) * wid.view(-1, 1, 1)\n",
    "    y_bin = (torch.arange(roi_size[0] - 1, -1, -1).float().to(bboxes.device) + 0.5) / roi_size[0] - 0.5\n",
    "    offset[:, :, :, 1] = y_bin.view(1, -1, 1) * hgt.view(-1, 1, 1)\n",
    "\n",
    "    rot_mat = rot_mat.view(num_bboxes, 1, 1, 2, 2)\n",
    "    offset = offset.view(num_bboxes, roi_size[0], roi_size[1], 2, 1)\n",
    "    offset = torch.matmul(rot_mat, offset).view(num_bboxes, roi_size[0], roi_size[1], 2)\n",
    "\n",
    "    x = cx.view(-1, 1, 1) + offset[:, :, :, 0]\n",
    "    y = cy.view(-1, 1, 1) + offset[:, :, :, 1]\n",
    "    x = x.view(-1)\n",
    "    y = y.view(-1)\n",
    "\n",
    "    x_min, x_max, y_min, y_max = pts_range[:4]\n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    y = (y_max - y) / (y_max - y_min)\n",
    "\n",
    "    fm_c, fm_h, fm_w = fm.size()\n",
    "    feat = fm.new().float().resize_(num_bboxes * roi_size[0] * roi_size[1], fm_c)\n",
    "    mask = (x > 0) * (x < 1) * (y > 0) * (y < 1)\n",
    "    x = x[mask]\n",
    "    y = y[mask]\n",
    "\n",
    "    xlw, xli, xhw, xhi = linear_interp(x, fm_w)\n",
    "    ylw, yli, yhw, yhi = linear_interp(y, fm_h)\n",
    "    feat[mask] = \\\n",
    "        (xlw * ylw).unsqueeze(1) * fm[:, yli, xli].transpose(0, 1) +\\\n",
    "        (xlw * yhw).unsqueeze(1) * fm[:, yhi, xli].transpose(0, 1) +\\\n",
    "        (xhw * ylw).unsqueeze(1) * fm[:, yli, xhi].transpose(0, 1) +\\\n",
    "        (xhw * yhw).unsqueeze(1) * fm[:, yhi, xhi].transpose(0, 1)\n",
    "    feat[torch.logical_not(mask)] = 0\n",
    "    feat = feat.view(num_bboxes, roi_size[0] * roi_size[1], fm_c)\n",
    "    feat = feat.transpose(1, 2).contiguous().view(num_bboxes, -1, roi_size[0], roi_size[1])\n",
    "    return feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ebf6240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from fractions import gcd\n",
    "from numbers import Number\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from numpy import float64, ndarray\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "\n",
    "\n",
    "### config ###\n",
    "config = dict()\n",
    "\"\"\"Train\"\"\"\n",
    "config[\"display_iters\"] = 205942\n",
    "config[\"val_iters\"] = 205942 * 2\n",
    "config[\"save_freq\"] = 1.0\n",
    "config[\"epoch\"] = 0\n",
    "config[\"horovod\"] = True\n",
    "config[\"opt\"] = \"adam\"\n",
    "config[\"num_epochs\"] = 36\n",
    "config[\"lr\"] = [1e-3, 1e-4]\n",
    "config[\"lr_epochs\"] = [32]\n",
    "#config[\"lr_func\"] = StepLR(config[\"lr\"], config[\"lr_epochs\"])\n",
    "\n",
    "\n",
    "config[\"batch_size\"] = 32\n",
    "config[\"val_batch_size\"] = 32\n",
    "config[\"workers\"] = 0\n",
    "config[\"val_workers\"] = config[\"workers\"]\n",
    "\n",
    "\n",
    "\"\"\"Model\"\"\"\n",
    "config[\"rot_aug\"] = False\n",
    "config[\"pred_range\"] = [-100.0, 100.0, -100.0, 100.0]\n",
    "config[\"num_scales\"] = 6\n",
    "config[\"n_actor\"] = 128\n",
    "config[\"n_map\"] = 128\n",
    "config[\"actor2map_dist\"] = 7.0\n",
    "config[\"map2actor_dist\"] = 6.0\n",
    "config[\"actor2actor_dist\"] = 100.0\n",
    "config[\"pred_size\"] = 30\n",
    "config[\"pred_step\"] = 1\n",
    "config[\"num_preds\"] = config[\"pred_size\"] // config[\"pred_step\"]\n",
    "config[\"num_mods\"] = 6\n",
    "config[\"cls_coef\"] = 1.0\n",
    "config[\"reg_coef\"] = 1.0\n",
    "config[\"mgn\"] = 0.2\n",
    "config[\"cls_th\"] = 2.0\n",
    "config[\"cls_ignore\"] = 0.2\n",
    "### end of config ###\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Lane Graph Network contains following components:\n",
    "        1. ActorNet: a 1D CNN to process the trajectory input\n",
    "        2. MapNet: LaneGraphCNN to learn structured map representations \n",
    "           from vectorized map data\n",
    "        3. Actor-Map Fusion Cycle: fuse the information between actor nodes \n",
    "           and lane nodes:\n",
    "            a. A2M: introduces real-time traffic information to \n",
    "                lane nodes, such as blockage or usage of the lanes\n",
    "            b. M2M:  updates lane node features by propagating the \n",
    "                traffic information over lane graphs\n",
    "            c. M2A: fuses updated map features with real-time traffic \n",
    "                information back to actors\n",
    "            d. A2A: handles the interaction between actors and produces\n",
    "                the output actor features\n",
    "        4. PredNet: prediction header for motion forecasting using \n",
    "           feature from A2A\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(Net, self).__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.actor_net = ActorNet(config)\n",
    "        self.map_net = MapNet(config)\n",
    "\n",
    "        #self.a2m = A2M(config)\n",
    "        #self.m2m = M2M(config)\n",
    "        self.m2a = M2A(config)\n",
    "        self.a2a = A2A(config)\n",
    "\n",
    "        self.pred_net = PredNet(config)\n",
    "\n",
    "    def forward(self, data: Dict) -> Dict[str, List[Tensor]]:\n",
    "        # construct actor feature\n",
    "        actors, actor_idcs = actor_gather(gpu(data[\"feats\"]))\n",
    "        actor_ctrs = gpu(data[\"ctrs\"])\n",
    "        actors = self.actor_net(actors)\n",
    "\n",
    "        # construct map features\n",
    "        graph = graph_gather(to_long(gpu(data[\"graph\"])))\n",
    "        nodes, node_idcs, node_ctrs = self.map_net(graph)\n",
    "\n",
    "        # actor-map fusion cycle \n",
    "        #nodes = self.a2m(nodes, graph, actors, actor_idcs, actor_ctrs)\n",
    "        #nodes = self.m2m(nodes, graph)\n",
    "        actors = self.m2a(actors, actor_idcs, actor_ctrs, nodes, node_idcs, node_ctrs)\n",
    "        actors = self.a2a(actors, actor_idcs, actor_ctrs)\n",
    "\n",
    "        # prediction\n",
    "        out = self.pred_net(actors, actor_idcs, actor_ctrs)\n",
    "        rot, orig = gpu(data[\"rot\"]), gpu(data[\"orig\"])\n",
    "        # transform prediction to world coordinates\n",
    "        for i in range(len(out[\"reg\"])):\n",
    "            out[\"reg\"][i] = torch.matmul(out[\"reg\"][i], rot[i]) + orig[i].view(\n",
    "                1, 1, 1, -1\n",
    "            )\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "def actor_gather(actors: List[Tensor]) -> Tuple[Tensor, List[Tensor]]:\n",
    "    batch_size = len(actors)\n",
    "    num_actors = [len(x) for x in actors]\n",
    "\n",
    "    actors = [x.transpose(1, 2) for x in actors]\n",
    "    actors = torch.cat(actors, 0)\n",
    "\n",
    "    actor_idcs = []\n",
    "    count = 0\n",
    "    for i in range(batch_size):\n",
    "        idcs = torch.arange(count, count + num_actors[i]).to(actors.device)\n",
    "        actor_idcs.append(idcs)\n",
    "        count += num_actors[i]\n",
    "    return actors, actor_idcs\n",
    "\n",
    "\n",
    "def graph_gather(graphs):\n",
    "    batch_size = len(graphs)\n",
    "    node_idcs = []\n",
    "    count = 0\n",
    "    counts = []\n",
    "    for i in range(batch_size):\n",
    "        counts.append(count)\n",
    "        idcs = torch.arange(count, count + graphs[i][\"num_nodes\"]).to(\n",
    "            graphs[i][\"feats\"].device\n",
    "        )\n",
    "        node_idcs.append(idcs)\n",
    "        count = count + graphs[i][\"num_nodes\"]\n",
    "\n",
    "    graph = dict()\n",
    "    graph[\"idcs\"] = node_idcs\n",
    "    graph[\"ctrs\"] = [x[\"ctrs\"] for x in graphs]\n",
    "\n",
    "    for key in [\"feats\", \"turn\", \"control\", \"intersect\"]:\n",
    "        graph[key] = torch.cat([x[key] for x in graphs], 0)\n",
    "\n",
    "    for k1 in [\"pre\", \"suc\"]:\n",
    "        graph[k1] = []\n",
    "        for i in range(len(graphs[0][\"pre\"])):\n",
    "            graph[k1].append(dict())\n",
    "            for k2 in [\"u\", \"v\"]:\n",
    "                graph[k1][i][k2] = torch.cat(\n",
    "                    [graphs[j][k1][i][k2] + counts[j] for j in range(batch_size)], 0\n",
    "                )\n",
    "\n",
    "    for k1 in [\"left\", \"right\"]:\n",
    "        graph[k1] = dict()\n",
    "        for k2 in [\"u\", \"v\"]:\n",
    "            temp = [graphs[i][k1][k2] + counts[i] for i in range(batch_size)]\n",
    "            temp = [\n",
    "                x if x.dim() > 0 else graph[\"pre\"][0][\"u\"].new().resize_(0)\n",
    "                for x in temp\n",
    "            ]\n",
    "            graph[k1][k2] = torch.cat(temp)\n",
    "    return graph\n",
    "\n",
    "\n",
    "class ActorNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Actor feature extractor with Conv1D\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(ActorNet, self).__init__()\n",
    "        self.config = config\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        n_in = 3\n",
    "        n_out = [32, 64, 128]\n",
    "        blocks = [Res1d, Res1d, Res1d]\n",
    "        num_blocks = [2, 2, 2]\n",
    "\n",
    "        groups = []\n",
    "        for i in range(len(num_blocks)):\n",
    "            group = []\n",
    "            if i == 0:\n",
    "                group.append(blocks[i](n_in, n_out[i], norm=norm, ng=ng))\n",
    "            else:\n",
    "                group.append(blocks[i](n_in, n_out[i], stride=2, norm=norm, ng=ng))\n",
    "\n",
    "            for j in range(1, num_blocks[i]):\n",
    "                group.append(blocks[i](n_out[i], n_out[i], norm=norm, ng=ng))\n",
    "            groups.append(nn.Sequential(*group))\n",
    "            n_in = n_out[i]\n",
    "        self.groups = nn.ModuleList(groups)\n",
    "\n",
    "        n = config[\"n_actor\"]\n",
    "        lateral = []\n",
    "        for i in range(len(n_out)):\n",
    "            lateral.append(Conv1d(n_out[i], n, norm=norm, ng=ng, act=False))\n",
    "        self.lateral = nn.ModuleList(lateral)\n",
    "\n",
    "        self.output = Res1d(n, n, norm=norm, ng=ng)\n",
    "\n",
    "    def forward(self, actors: Tensor) -> Tensor:\n",
    "        out = actors\n",
    "\n",
    "        outputs = []\n",
    "        for i in range(len(self.groups)):\n",
    "            out = self.groups[i](out)\n",
    "            outputs.append(out)\n",
    "\n",
    "        out = self.lateral[-1](outputs[-1])\n",
    "        for i in range(len(outputs) - 2, -1, -1):\n",
    "            out = F.interpolate(out, scale_factor=2, mode=\"linear\", align_corners=False)\n",
    "            out += self.lateral[i](outputs[i])\n",
    "\n",
    "        out = self.output(out)[:, :, -1]\n",
    "        return out\n",
    "\n",
    "\n",
    "class MapNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Map Graph feature extractor with LaneGraphCNN\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(MapNet, self).__init__()\n",
    "        self.config = config\n",
    "        n_map = config[\"n_map\"]\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        self.input = nn.Sequential(\n",
    "            nn.Linear(2, n_map),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Linear(n_map, n_map, norm=norm, ng=ng, act=False),\n",
    "        )\n",
    "        self.seg = nn.Sequential(\n",
    "            nn.Linear(2, n_map),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Linear(n_map, n_map, norm=norm, ng=ng, act=False),\n",
    "        )\n",
    "\n",
    "        keys = [\"ctr\", \"norm\", \"ctr2\", \"left\", \"right\"]\n",
    "        for i in range(config[\"num_scales\"]):\n",
    "            keys.append(\"pre\" + str(i))\n",
    "            keys.append(\"suc\" + str(i))\n",
    "\n",
    "        fuse = dict()\n",
    "        for key in keys:\n",
    "            fuse[key] = []\n",
    "\n",
    "        for i in range(2):\n",
    "            for key in fuse:\n",
    "                if key in [\"norm\"]:\n",
    "                    fuse[key].append(nn.GroupNorm(gcd(ng, n_map), n_map))\n",
    "                elif key in [\"ctr2\"]:\n",
    "                    fuse[key].append(Linear(n_map, n_map, norm=norm, ng=ng, act=False))\n",
    "                else:\n",
    "                    fuse[key].append(nn.Linear(n_map, n_map, bias=False))\n",
    "\n",
    "        for key in fuse:\n",
    "            fuse[key] = nn.ModuleList(fuse[key])\n",
    "        self.fuse = nn.ModuleDict(fuse)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, graph):\n",
    "        if (\n",
    "            len(graph[\"feats\"]) == 0\n",
    "            or len(graph[\"pre\"][-1][\"u\"]) == 0\n",
    "            or len(graph[\"suc\"][-1][\"u\"]) == 0\n",
    "        ):\n",
    "            temp = graph[\"feats\"]\n",
    "            return (\n",
    "                temp.new().resize_(0),\n",
    "                [temp.new().long().resize_(0) for x in graph[\"node_idcs\"]],\n",
    "                temp.new().resize_(0),\n",
    "            )\n",
    "\n",
    "        ctrs = torch.cat(graph[\"ctrs\"], 0)\n",
    "        feat = self.input(ctrs)\n",
    "        feat += self.seg(graph[\"feats\"])\n",
    "        feat = self.relu(feat)\n",
    "\n",
    "        \"\"\"fuse map\"\"\"\n",
    "        res = feat\n",
    "        for i in range(len(self.fuse[\"ctr\"])):\n",
    "            temp = self.fuse[\"ctr\"][i](feat)\n",
    "            for key in self.fuse:\n",
    "                if key.startswith(\"pre\") or key.startswith(\"suc\"):\n",
    "                    k1 = key[:3]\n",
    "                    k2 = int(key[3:])\n",
    "                    temp.index_add_(\n",
    "                        0,\n",
    "                        graph[k1][k2][\"u\"],\n",
    "                        self.fuse[key][i](feat[graph[k1][k2][\"v\"]]),\n",
    "                    )\n",
    "\n",
    "            if len(graph[\"left\"][\"u\"] > 0):\n",
    "                temp.index_add_(\n",
    "                    0,\n",
    "                    graph[\"left\"][\"u\"],\n",
    "                    self.fuse[\"left\"][i](feat[graph[\"left\"][\"v\"]]),\n",
    "                )\n",
    "            if len(graph[\"right\"][\"u\"] > 0):\n",
    "                temp.index_add_(\n",
    "                    0,\n",
    "                    graph[\"right\"][\"u\"],\n",
    "                    self.fuse[\"right\"][i](feat[graph[\"right\"][\"v\"]]),\n",
    "                )\n",
    "\n",
    "            feat = self.fuse[\"norm\"][i](temp)\n",
    "            feat = self.relu(feat)\n",
    "\n",
    "            feat = self.fuse[\"ctr2\"][i](feat)\n",
    "            feat += res\n",
    "            feat = self.relu(feat)\n",
    "            res = feat\n",
    "        return feat, graph[\"idcs\"], graph[\"ctrs\"]\n",
    "\n",
    "\n",
    "class A2M(nn.Module):\n",
    "    \"\"\"\n",
    "    Actor to Map Fusion:  fuses real-time traffic information from\n",
    "    actor nodes to lane nodes\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(A2M, self).__init__()\n",
    "        self.config = config\n",
    "        n_map = config[\"n_map\"]\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        \"\"\"fuse meta, static, dyn\"\"\"\n",
    "        self.meta = Linear(n_map + 4, n_map, norm=norm, ng=ng)\n",
    "        att = []\n",
    "        for i in range(2):\n",
    "            att.append(Att(n_map, config[\"n_actor\"]))\n",
    "        self.att = nn.ModuleList(att)\n",
    "\n",
    "    def forward(self, feat: Tensor, graph: Dict[str, Union[List[Tensor], Tensor, List[Dict[str, Tensor]], Dict[str, Tensor]]], actors: Tensor, actor_idcs: List[Tensor], actor_ctrs: List[Tensor]) -> Tensor:\n",
    "        \"\"\"meta, static and dyn fuse using attention\"\"\"\n",
    "        meta = torch.cat(\n",
    "            (\n",
    "                graph[\"turn\"],\n",
    "                graph[\"control\"].unsqueeze(1),\n",
    "                graph[\"intersect\"].unsqueeze(1),\n",
    "            ),\n",
    "            1,\n",
    "        )\n",
    "        feat = self.meta(torch.cat((feat, meta), 1))\n",
    "\n",
    "        for i in range(len(self.att)):\n",
    "            feat = self.att[i](\n",
    "                feat,\n",
    "                graph[\"idcs\"],\n",
    "                graph[\"ctrs\"],\n",
    "                actors,\n",
    "                actor_idcs,\n",
    "                actor_ctrs,\n",
    "                self.config[\"actor2map_dist\"],\n",
    "            )\n",
    "        return feat\n",
    "\n",
    "\n",
    "class M2M(nn.Module):\n",
    "    \"\"\"\n",
    "    The lane to lane block: propagates information over lane\n",
    "            graphs and updates the features of lane nodes\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(M2M, self).__init__()\n",
    "        self.config = config\n",
    "        n_map = config[\"n_map\"]\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        keys = [\"ctr\", \"norm\", \"ctr2\", \"left\", \"right\"]\n",
    "        for i in range(config[\"num_scales\"]):\n",
    "            keys.append(\"pre\" + str(i))\n",
    "            keys.append(\"suc\" + str(i))\n",
    "\n",
    "        fuse = dict()\n",
    "        for key in keys:\n",
    "            fuse[key] = []\n",
    "\n",
    "        for i in range(4):\n",
    "            for key in fuse:\n",
    "                if key in [\"norm\"]:\n",
    "                    fuse[key].append(nn.GroupNorm(gcd(ng, n_map), n_map))\n",
    "                elif key in [\"ctr2\"]:\n",
    "                    fuse[key].append(Linear(n_map, n_map, norm=norm, ng=ng, act=False))\n",
    "                else:\n",
    "                    fuse[key].append(nn.Linear(n_map, n_map, bias=False))\n",
    "\n",
    "        for key in fuse:\n",
    "            fuse[key] = nn.ModuleList(fuse[key])\n",
    "        self.fuse = nn.ModuleDict(fuse)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, feat: Tensor, graph: Dict) -> Tensor:\n",
    "        \"\"\"fuse map\"\"\"\n",
    "        res = feat\n",
    "        for i in range(len(self.fuse[\"ctr\"])):\n",
    "            temp = self.fuse[\"ctr\"][i](feat)\n",
    "            for key in self.fuse:\n",
    "                if key.startswith(\"pre\") or key.startswith(\"suc\"):\n",
    "                    k1 = key[:3]\n",
    "                    k2 = int(key[3:])\n",
    "                    temp.index_add_(\n",
    "                        0,\n",
    "                        graph[k1][k2][\"u\"],\n",
    "                        self.fuse[key][i](feat[graph[k1][k2][\"v\"]]),\n",
    "                    )\n",
    "\n",
    "            if len(graph[\"left\"][\"u\"] > 0):\n",
    "                temp.index_add_(\n",
    "                    0,\n",
    "                    graph[\"left\"][\"u\"],\n",
    "                    self.fuse[\"left\"][i](feat[graph[\"left\"][\"v\"]]),\n",
    "                )\n",
    "            if len(graph[\"right\"][\"u\"] > 0):\n",
    "                temp.index_add_(\n",
    "                    0,\n",
    "                    graph[\"right\"][\"u\"],\n",
    "                    self.fuse[\"right\"][i](feat[graph[\"right\"][\"v\"]]),\n",
    "                )\n",
    "\n",
    "            feat = self.fuse[\"norm\"][i](temp)\n",
    "            feat = self.relu(feat)\n",
    "\n",
    "            feat = self.fuse[\"ctr2\"][i](feat)\n",
    "            feat += res\n",
    "            feat = self.relu(feat)\n",
    "            res = feat\n",
    "        return feat\n",
    "\n",
    "\n",
    "class M2A(nn.Module):\n",
    "    \"\"\"\n",
    "    The lane to actor block fuses updated\n",
    "        map information from lane nodes to actor nodes\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(M2A, self).__init__()\n",
    "        self.config = config\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        n_actor = config[\"n_actor\"]\n",
    "        n_map = config[\"n_map\"]\n",
    "\n",
    "        att = []\n",
    "        for i in range(2):\n",
    "            att.append(Att(n_actor, n_map))\n",
    "        self.att = nn.ModuleList(att)\n",
    "\n",
    "    def forward(self, actors: Tensor, actor_idcs: List[Tensor], actor_ctrs: List[Tensor], nodes: Tensor, node_idcs: List[Tensor], node_ctrs: List[Tensor]) -> Tensor:\n",
    "        for i in range(len(self.att)):\n",
    "            actors = self.att[i](\n",
    "                actors,\n",
    "                actor_idcs,\n",
    "                actor_ctrs,\n",
    "                nodes,\n",
    "                node_idcs,\n",
    "                node_ctrs,\n",
    "                self.config[\"map2actor_dist\"],\n",
    "            )\n",
    "        return actors\n",
    "\n",
    "\n",
    "class A2A(nn.Module):\n",
    "    \"\"\"\n",
    "    The actor to actor block performs interactions among actors.\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(A2A, self).__init__()\n",
    "        self.config = config\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        n_actor = config[\"n_actor\"]\n",
    "        n_map = config[\"n_map\"]\n",
    "\n",
    "        att = []\n",
    "        for i in range(2):\n",
    "            att.append(Att(n_actor, n_actor))\n",
    "        self.att = nn.ModuleList(att)\n",
    "\n",
    "    def forward(self, actors: Tensor, actor_idcs: List[Tensor], actor_ctrs: List[Tensor]) -> Tensor:\n",
    "        for i in range(len(self.att)):\n",
    "            actors = self.att[i](\n",
    "                actors,\n",
    "                actor_idcs,\n",
    "                actor_ctrs,\n",
    "                actors,\n",
    "                actor_idcs,\n",
    "                actor_ctrs,\n",
    "                self.config[\"actor2actor_dist\"],\n",
    "            )\n",
    "        return actors\n",
    "\n",
    "\n",
    "class EncodeDist(nn.Module):\n",
    "    def __init__(self, n, linear=True):\n",
    "        super(EncodeDist, self).__init__()\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        block = [nn.Linear(2, n), nn.ReLU(inplace=True)]\n",
    "\n",
    "        if linear:\n",
    "            block.append(nn.Linear(n, n))\n",
    "\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, dist):\n",
    "        x, y = dist[:, :1], dist[:, 1:]\n",
    "        dist = torch.cat(\n",
    "            (\n",
    "                torch.sign(x) * torch.log(torch.abs(x) + 1.0),\n",
    "                torch.sign(y) * torch.log(torch.abs(y) + 1.0),\n",
    "            ),\n",
    "            1,\n",
    "        )\n",
    "\n",
    "        dist = self.block(dist)\n",
    "        return dist\n",
    "\n",
    "\n",
    "class PredNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Final motion forecasting with Linear Residual block\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(PredNet, self).__init__()\n",
    "        self.config = config\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        n_actor = config[\"n_actor\"]\n",
    "\n",
    "        pred = []\n",
    "        for i in range(config[\"num_mods\"]):\n",
    "            pred.append(\n",
    "                nn.Sequential(\n",
    "                    LinearRes(n_actor, n_actor, norm=norm, ng=ng),\n",
    "                    nn.Linear(n_actor, 2 * config[\"num_preds\"]),\n",
    "                )\n",
    "            )\n",
    "        self.pred = nn.ModuleList(pred)\n",
    "\n",
    "        self.att_dest = AttDest(n_actor)\n",
    "        self.cls = nn.Sequential(\n",
    "            LinearRes(n_actor, n_actor, norm=norm, ng=ng), nn.Linear(n_actor, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, actors: Tensor, actor_idcs: List[Tensor], actor_ctrs: List[Tensor]) -> Dict[str, List[Tensor]]:\n",
    "        preds = []\n",
    "        for i in range(len(self.pred)):\n",
    "            preds.append(self.pred[i](actors))\n",
    "        reg = torch.cat([x.unsqueeze(1) for x in preds], 1)\n",
    "        reg = reg.view(reg.size(0), reg.size(1), -1, 2)\n",
    "\n",
    "        for i in range(len(actor_idcs)):\n",
    "            idcs = actor_idcs[i]\n",
    "            ctrs = actor_ctrs[i].view(-1, 1, 1, 2)\n",
    "            reg[idcs] = reg[idcs] + ctrs\n",
    "\n",
    "        dest_ctrs = reg[:, :, -1].detach()\n",
    "        feats = self.att_dest(actors, torch.cat(actor_ctrs, 0), dest_ctrs)\n",
    "        cls = self.cls(feats).view(-1, self.config[\"num_mods\"])\n",
    "\n",
    "        cls, sort_idcs = cls.sort(1, descending=True)\n",
    "        row_idcs = torch.arange(len(sort_idcs)).long().to(sort_idcs.device)\n",
    "        row_idcs = row_idcs.view(-1, 1).repeat(1, sort_idcs.size(1)).view(-1)\n",
    "        sort_idcs = sort_idcs.view(-1)\n",
    "        reg = reg[row_idcs, sort_idcs].view(cls.size(0), cls.size(1), -1, 2)\n",
    "\n",
    "        out = dict()\n",
    "        out[\"cls\"], out[\"reg\"] = [], []\n",
    "        for i in range(len(actor_idcs)):\n",
    "            idcs = actor_idcs[i]\n",
    "            ctrs = actor_ctrs[i].view(-1, 1, 1, 2)\n",
    "            out[\"cls\"].append(cls[idcs])\n",
    "            out[\"reg\"].append(reg[idcs])\n",
    "        return out\n",
    "\n",
    "\n",
    "class Att(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention block to pass context nodes information to target nodes\n",
    "    This is used in Actor2Map, Actor2Actor, Map2Actor and Map2Map\n",
    "    \"\"\"\n",
    "    def __init__(self, n_agt: int, n_ctx: int) -> None:\n",
    "        super(Att, self).__init__()\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        self.dist = nn.Sequential(\n",
    "            nn.Linear(2, n_ctx),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Linear(n_ctx, n_ctx, norm=norm, ng=ng),\n",
    "        )\n",
    "\n",
    "        self.query = Linear(n_agt, n_ctx, norm=norm, ng=ng)\n",
    "\n",
    "        self.ctx = nn.Sequential(\n",
    "            Linear(3 * n_ctx, n_agt, norm=norm, ng=ng),\n",
    "            nn.Linear(n_agt, n_agt, bias=False),\n",
    "        )\n",
    "\n",
    "        self.agt = nn.Linear(n_agt, n_agt, bias=False)\n",
    "        self.norm = nn.GroupNorm(gcd(ng, n_agt), n_agt)\n",
    "        self.linear = Linear(n_agt, n_agt, norm=norm, ng=ng, act=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, agts: Tensor, agt_idcs: List[Tensor], agt_ctrs: List[Tensor], ctx: Tensor, ctx_idcs: List[Tensor], ctx_ctrs: List[Tensor], dist_th: float) -> Tensor:\n",
    "        res = agts\n",
    "        if len(ctx) == 0:\n",
    "            agts = self.agt(agts)\n",
    "            agts = self.relu(agts)\n",
    "            agts = self.linear(agts)\n",
    "            agts += res\n",
    "            agts = self.relu(agts)\n",
    "            return agts\n",
    "\n",
    "        batch_size = len(agt_idcs)\n",
    "        hi, wi = [], []\n",
    "        hi_count, wi_count = 0, 0\n",
    "        for i in range(batch_size):\n",
    "            dist = agt_ctrs[i].view(-1, 1, 2) - ctx_ctrs[i].view(1, -1, 2)\n",
    "            dist = torch.sqrt((dist ** 2).sum(2))\n",
    "            mask = dist <= dist_th\n",
    "\n",
    "            idcs = torch.nonzero(mask, as_tuple=False)\n",
    "            if len(idcs) == 0:\n",
    "                continue\n",
    "\n",
    "            hi.append(idcs[:, 0] + hi_count)\n",
    "            wi.append(idcs[:, 1] + wi_count)\n",
    "            hi_count += len(agt_idcs[i])\n",
    "            wi_count += len(ctx_idcs[i])\n",
    "        hi = torch.cat(hi, 0)\n",
    "        wi = torch.cat(wi, 0)\n",
    "\n",
    "        agt_ctrs = torch.cat(agt_ctrs, 0)\n",
    "        ctx_ctrs = torch.cat(ctx_ctrs, 0)\n",
    "        dist = agt_ctrs[hi] - ctx_ctrs[wi]\n",
    "        dist = self.dist(dist)\n",
    "\n",
    "        query = self.query(agts[hi])\n",
    "\n",
    "        ctx = ctx[wi]\n",
    "        ctx = torch.cat((dist, query, ctx), 1)\n",
    "        ctx = self.ctx(ctx)\n",
    "\n",
    "        agts = self.agt(agts)\n",
    "        agts.index_add_(0, hi, ctx)\n",
    "        agts = self.norm(agts)\n",
    "        agts = self.relu(agts)\n",
    "\n",
    "        agts = self.linear(agts)\n",
    "        agts += res\n",
    "        agts = self.relu(agts)\n",
    "        return agts\n",
    "\n",
    "\n",
    "class AttDest(nn.Module):\n",
    "    def __init__(self, n_agt: int):\n",
    "        super(AttDest, self).__init__()\n",
    "        norm = \"GN\"\n",
    "        ng = 1\n",
    "\n",
    "        self.dist = nn.Sequential(\n",
    "            nn.Linear(2, n_agt),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Linear(n_agt, n_agt, norm=norm, ng=ng),\n",
    "        )\n",
    "\n",
    "        self.agt = Linear(2 * n_agt, n_agt, norm=norm, ng=ng)\n",
    "\n",
    "    def forward(self, agts: Tensor, agt_ctrs: Tensor, dest_ctrs: Tensor) -> Tensor:\n",
    "        n_agt = agts.size(1)\n",
    "        num_mods = dest_ctrs.size(1)\n",
    "\n",
    "        dist = (agt_ctrs.unsqueeze(1) - dest_ctrs).view(-1, 2)\n",
    "        dist = self.dist(dist)\n",
    "        agts = agts.unsqueeze(1).repeat(1, num_mods, 1).view(-1, n_agt)\n",
    "\n",
    "        agts = torch.cat((dist, agts), 1)\n",
    "        agts = self.agt(agts)\n",
    "        return agts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c6890b",
   "metadata": {},
   "source": [
    "## COUNT PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75d93615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd483cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANEGCN-- 1842601\n",
      "DENSE-TNT-- 1052225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_288073/1847853586.py:149: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  self.bn1 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
      "/tmp/ipykernel_288073/1847853586.py:150: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  self.bn2 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
      "/tmp/ipykernel_288073/1847853586.py:161: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  nn.GroupNorm(gcd(ng, n_out), n_out))\n",
      "/tmp/ipykernel_288073/1847853586.py:44: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  self.norm = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
      "/tmp/ipykernel_288073/1847853586.py:69: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  self.norm = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
      "/tmp/ipykernel_288073/528811386.py:262: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  fuse[key].append(nn.GroupNorm(gcd(ng, n_map), n_map))\n",
      "/tmp/ipykernel_288073/528811386.py:620: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  self.norm = nn.GroupNorm(gcd(ng, n_agt), n_agt)\n",
      "/tmp/ipykernel_288073/1847853586.py:199: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  self.norm1 = nn.GroupNorm(gcd(ng, n_out), n_out)\n",
      "/tmp/ipykernel_288073/1847853586.py:200: DeprecationWarning: fractions.gcd() is deprecated. Use math.gcd() instead.\n",
      "  self.norm2 = nn.GroupNorm(gcd(ng, n_out), n_out)\n"
     ]
    }
   ],
   "source": [
    "model_lanegcn_ours = Net(config)\n",
    "print(\"LANEGCN--\", count_parameters(model_lanegcn_ours)) #Original-LaneGCN:3701161\n",
    "print(\"DENSE-TNT--\", count_parameters(model_densetnt)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1b3b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl_venv",
   "language": "python",
   "name": "ssl_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
